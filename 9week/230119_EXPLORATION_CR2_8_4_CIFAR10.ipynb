{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8f1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import utils\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7d03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 3-1: cifar10 데이터셋을 로드하고, 훈련 데이터셋에서 20%를 검증 데이터셋으로 분리합니다.\n",
    "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75e13d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 학습 데이터: (50000, 32, 32, 3) 레이블: (50000, 1)\n",
      "학습 데이터: (40000, 32, 32, 3) 레이블: (40000, 1)\n",
      "검증 데이터: (10000, 32, 32, 3) 레이블: (10000, 1)\n",
      "테스트 데이터: (10000, 32, 32, 3) 레이블: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.20, random_state=2023)\n",
    "# 훈련, 검증, 테스트 데이터와 레이블 종류가 몇개인지 출력합니다.\n",
    "print(\"전체 학습 데이터: {} 레이블: {}\".format(x_train_full.shape, y_train_full.shape))\n",
    "print(\"학습 데이터: {} 레이블: {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"검증 데이터: {} 레이블: {}\".format(x_val.shape, y_val.shape))\n",
    "print(\"테스트 데이터: {} 레이블: {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea54d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10의 분류에 해당하는 'airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "# 'dog', 'frog', 'horse', 'ship', 'truck'를 class_name으로 정의합니다.\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f41bae02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 데이터의 0번째인 x_train[0]를 이미지로 시각화합니다.\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2b0a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# 훈련, 검증, 테스트 데이터의 형태(shape)을 출력합니다.\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95f4ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3072)\n",
      "(10000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# 문제 3-2: 훈련, 검증, 테스트 데이터의 형태(shape)을 32 * 32 * 3 = 3072로 변형합니다.\n",
    "x_train = x_train.reshape(-1, 32*32*3)\n",
    "x_val = x_val.reshape(-1, 32*32*3)\n",
    "x_test = x_test.reshape(-1, 32*32*3)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688333bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7,   7,   6, ..., 197, 196, 199], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a990ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증, 테스트 데이터를 255로 나누어 0~1 사이의 값으로 변환합니다.\n",
    "x_train = x_train / 255.\n",
    "x_val = x_val / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f1f397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3072)\n",
      "(10000, 3072)\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4e2fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02745098, 0.02745098, 0.02352941, ..., 0.77254902, 0.76862745,\n",
       "       0.78039216])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a733de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,630,666\n",
      "Trainable params: 2,629,642\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n"
     ]
    }
   ],
   "source": [
    "# 문제 3-3: BatchNormalization과 Dropout을 적용하여 빠른 학습과 과대적합을 방지하고,\n",
    "# 10개의 이미지를 분류하는 딥러닝 모델을 구성합니다.\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=(3072, )))\n",
    "\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(1024))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.save('thankyoualls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d036e9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "40/40 [==============================] - 2s 23ms/step - loss: 2.1381 - accuracy: 0.1255 - val_loss: 2.2885 - val_accuracy: 0.1175\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 2/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.9261 - accuracy: 0.1133 - val_loss: 2.8295 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.8778 - accuracy: 0.1080 - val_loss: 1.9788 - val_accuracy: 0.0202\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 4/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.8350 - accuracy: 0.1016 - val_loss: 1.8000 - val_accuracy: 0.1759\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 5/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.8038 - accuracy: 0.0972 - val_loss: 1.9379 - val_accuracy: 0.0802\n",
      "Epoch 6/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.7791 - accuracy: 0.0935 - val_loss: 2.1796 - val_accuracy: 0.2560\n",
      "Epoch 7/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.7594 - accuracy: 0.0999 - val_loss: 1.7695 - val_accuracy: 0.0627\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 8/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.7242 - accuracy: 0.0987 - val_loss: 1.8298 - val_accuracy: 0.0096\n",
      "Epoch 9/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.7197 - accuracy: 0.0965 - val_loss: 1.9830 - val_accuracy: 0.0864\n",
      "Epoch 10/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.6893 - accuracy: 0.1001 - val_loss: 1.6552 - val_accuracy: 0.0475\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 11/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.6699 - accuracy: 0.1000 - val_loss: 1.8451 - val_accuracy: 0.0434\n",
      "Epoch 12/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.6631 - accuracy: 0.0969 - val_loss: 1.7329 - val_accuracy: 0.0219\n",
      "Epoch 13/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.6376 - accuracy: 0.0972 - val_loss: 1.8137 - val_accuracy: 0.1036\n",
      "Epoch 14/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.6366 - accuracy: 0.0994 - val_loss: 1.7524 - val_accuracy: 0.1149\n",
      "Epoch 15/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.6204 - accuracy: 0.0957 - val_loss: 1.6343 - val_accuracy: 0.1815\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 16/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.6077 - accuracy: 0.0966 - val_loss: 1.9188 - val_accuracy: 0.0968\n",
      "Epoch 17/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.5904 - accuracy: 0.0966 - val_loss: 1.7197 - val_accuracy: 0.0768\n",
      "Epoch 18/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.5763 - accuracy: 0.0985 - val_loss: 1.9728 - val_accuracy: 0.1463\n",
      "Epoch 19/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.5644 - accuracy: 0.0980 - val_loss: 1.7056 - val_accuracy: 0.1789\n",
      "Epoch 20/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.5557 - accuracy: 0.0984 - val_loss: 1.9249 - val_accuracy: 0.1451\n",
      "Epoch 21/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.5513 - accuracy: 0.0963 - val_loss: 1.7553 - val_accuracy: 0.1098\n",
      "Epoch 22/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.5401 - accuracy: 0.0968 - val_loss: 1.7954 - val_accuracy: 0.0875\n",
      "Epoch 23/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.5290 - accuracy: 0.0962 - val_loss: 2.3479 - val_accuracy: 0.0162\n",
      "Epoch 24/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.5233 - accuracy: 0.0971 - val_loss: 1.8250 - val_accuracy: 0.3023\n",
      "Epoch 25/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.5115 - accuracy: 0.0972 - val_loss: 1.7380 - val_accuracy: 0.0505\n",
      "Epoch 26/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.5000 - accuracy: 0.0965 - val_loss: 1.6131 - val_accuracy: 0.0633\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 27/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4916 - accuracy: 0.0967 - val_loss: 1.6966 - val_accuracy: 0.0453\n",
      "Epoch 28/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4828 - accuracy: 0.0993 - val_loss: 1.8179 - val_accuracy: 0.0107\n",
      "Epoch 29/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4711 - accuracy: 0.0951 - val_loss: 1.9111 - val_accuracy: 0.0573\n",
      "Epoch 30/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4668 - accuracy: 0.0955 - val_loss: 1.6182 - val_accuracy: 0.1140\n",
      "Epoch 31/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4636 - accuracy: 0.0979 - val_loss: 1.9265 - val_accuracy: 0.3235\n",
      "Epoch 32/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.4560 - accuracy: 0.0977 - val_loss: 1.6698 - val_accuracy: 0.1161\n",
      "Epoch 33/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4467 - accuracy: 0.0947 - val_loss: 1.6026 - val_accuracy: 0.1716\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 34/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4367 - accuracy: 0.0962 - val_loss: 1.5650 - val_accuracy: 0.1192\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 35/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.4363 - accuracy: 0.0971 - val_loss: 1.8276 - val_accuracy: 0.0467\n",
      "Epoch 36/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4301 - accuracy: 0.0974 - val_loss: 1.5573 - val_accuracy: 0.0510\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 37/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4191 - accuracy: 0.0952 - val_loss: 1.5023 - val_accuracy: 0.1097\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 38/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4190 - accuracy: 0.0990 - val_loss: 1.6462 - val_accuracy: 0.0308\n",
      "Epoch 39/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.4044 - accuracy: 0.0963 - val_loss: 1.7256 - val_accuracy: 0.0679\n",
      "Epoch 40/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.4042 - accuracy: 0.0989 - val_loss: 1.7248 - val_accuracy: 0.1986\n",
      "Epoch 41/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3918 - accuracy: 0.0997 - val_loss: 1.7174 - val_accuracy: 0.0023\n",
      "Epoch 42/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3943 - accuracy: 0.0963 - val_loss: 1.7198 - val_accuracy: 0.0238\n",
      "Epoch 43/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3799 - accuracy: 0.0960 - val_loss: 1.7464 - val_accuracy: 0.1310\n",
      "Epoch 44/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.3754 - accuracy: 0.0992 - val_loss: 1.6325 - val_accuracy: 0.0675\n",
      "Epoch 45/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3722 - accuracy: 0.0975 - val_loss: 1.9266 - val_accuracy: 0.1075\n",
      "Epoch 46/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3689 - accuracy: 0.0986 - val_loss: 2.3923 - val_accuracy: 0.0246\n",
      "Epoch 47/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3611 - accuracy: 0.0997 - val_loss: 2.1845 - val_accuracy: 0.1712\n",
      "Epoch 48/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3528 - accuracy: 0.0994 - val_loss: 1.5573 - val_accuracy: 0.0601\n",
      "Epoch 49/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.3422 - accuracy: 0.0975 - val_loss: 1.8797 - val_accuracy: 0.0797\n",
      "Epoch 50/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3495 - accuracy: 0.0968 - val_loss: 1.6101 - val_accuracy: 0.1015\n",
      "Epoch 51/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3392 - accuracy: 0.0967 - val_loss: 1.7135 - val_accuracy: 0.0299\n",
      "Epoch 52/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3354 - accuracy: 0.0987 - val_loss: 1.6605 - val_accuracy: 0.1226\n",
      "Epoch 53/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3374 - accuracy: 0.0981 - val_loss: 1.7474 - val_accuracy: 0.1980\n",
      "Epoch 54/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3287 - accuracy: 0.0987 - val_loss: 1.7430 - val_accuracy: 0.0126\n",
      "Epoch 55/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3173 - accuracy: 0.0981 - val_loss: 1.8267 - val_accuracy: 0.1295\n",
      "Epoch 56/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.3096 - accuracy: 0.0963 - val_loss: 1.8002 - val_accuracy: 0.0915\n",
      "Epoch 57/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3042 - accuracy: 0.0996 - val_loss: 1.5545 - val_accuracy: 0.1306\n",
      "Epoch 58/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.3071 - accuracy: 0.0986 - val_loss: 1.6388 - val_accuracy: 0.0694\n",
      "Epoch 59/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2994 - accuracy: 0.0996 - val_loss: 1.7545 - val_accuracy: 0.1151\n",
      "Epoch 60/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2921 - accuracy: 0.0979 - val_loss: 1.5150 - val_accuracy: 0.0801\n",
      "Epoch 61/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2888 - accuracy: 0.1004 - val_loss: 1.6719 - val_accuracy: 0.0460\n",
      "Epoch 62/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2892 - accuracy: 0.0992 - val_loss: 1.8190 - val_accuracy: 0.1162\n",
      "Epoch 63/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2889 - accuracy: 0.1004 - val_loss: 1.5412 - val_accuracy: 0.0277\n",
      "Epoch 64/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2753 - accuracy: 0.0966 - val_loss: 1.5550 - val_accuracy: 0.1562\n",
      "Epoch 65/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2642 - accuracy: 0.0984 - val_loss: 1.7677 - val_accuracy: 0.1403\n",
      "Epoch 66/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2717 - accuracy: 0.0987 - val_loss: 1.7190 - val_accuracy: 0.3710\n",
      "Epoch 67/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2653 - accuracy: 0.1007 - val_loss: 1.5426 - val_accuracy: 0.1147\n",
      "Epoch 68/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2589 - accuracy: 0.0994 - val_loss: 1.4464 - val_accuracy: 0.0977\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 69/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2506 - accuracy: 0.1000 - val_loss: 1.6464 - val_accuracy: 0.2105\n",
      "Epoch 70/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2492 - accuracy: 0.0998 - val_loss: 1.7179 - val_accuracy: 0.0318\n",
      "Epoch 71/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2403 - accuracy: 0.1015 - val_loss: 1.6789 - val_accuracy: 0.0322\n",
      "Epoch 72/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2393 - accuracy: 0.0991 - val_loss: 1.6243 - val_accuracy: 0.1105\n",
      "Epoch 73/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2258 - accuracy: 0.1002 - val_loss: 1.7817 - val_accuracy: 0.0400\n",
      "Epoch 74/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2276 - accuracy: 0.1006 - val_loss: 1.6379 - val_accuracy: 0.2928\n",
      "Epoch 75/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2291 - accuracy: 0.1018 - val_loss: 1.4847 - val_accuracy: 0.1111\n",
      "Epoch 76/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2191 - accuracy: 0.1016 - val_loss: 1.5124 - val_accuracy: 0.1434\n",
      "Epoch 77/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.2109 - accuracy: 0.1001 - val_loss: 1.6148 - val_accuracy: 0.0920\n",
      "Epoch 78/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.2124 - accuracy: 0.1006 - val_loss: 1.7749 - val_accuracy: 0.0139\n",
      "Epoch 79/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.2045 - accuracy: 0.1024 - val_loss: 1.5874 - val_accuracy: 0.0400\n",
      "Epoch 80/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2025 - accuracy: 0.0990 - val_loss: 1.6930 - val_accuracy: 0.0697\n",
      "Epoch 81/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.2034 - accuracy: 0.1007 - val_loss: 1.5203 - val_accuracy: 0.1529\n",
      "Epoch 82/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1979 - accuracy: 0.1006 - val_loss: 1.7802 - val_accuracy: 0.0304\n",
      "Epoch 83/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1949 - accuracy: 0.0996 - val_loss: 1.6186 - val_accuracy: 0.0387\n",
      "Epoch 84/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1892 - accuracy: 0.1014 - val_loss: 1.8639 - val_accuracy: 0.0679\n",
      "Epoch 85/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1798 - accuracy: 0.1008 - val_loss: 1.5212 - val_accuracy: 0.0487\n",
      "Epoch 86/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1719 - accuracy: 0.1010 - val_loss: 1.7191 - val_accuracy: 0.1928\n",
      "Epoch 87/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.1703 - accuracy: 0.1037 - val_loss: 1.6454 - val_accuracy: 0.0670\n",
      "Epoch 88/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.1736 - accuracy: 0.1018 - val_loss: 1.5155 - val_accuracy: 0.1193\n",
      "Epoch 89/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1670 - accuracy: 0.1009 - val_loss: 1.8234 - val_accuracy: 0.0306\n",
      "Epoch 90/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1622 - accuracy: 0.1001 - val_loss: 1.6082 - val_accuracy: 0.1066\n",
      "Epoch 91/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1575 - accuracy: 0.0994 - val_loss: 1.9802 - val_accuracy: 0.0502\n",
      "Epoch 92/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1546 - accuracy: 0.1011 - val_loss: 1.5698 - val_accuracy: 0.0449\n",
      "Epoch 93/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1525 - accuracy: 0.1009 - val_loss: 2.1353 - val_accuracy: 0.1337\n",
      "Epoch 94/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1481 - accuracy: 0.1011 - val_loss: 1.5987 - val_accuracy: 0.0457\n",
      "Epoch 95/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1400 - accuracy: 0.1013 - val_loss: 1.5502 - val_accuracy: 0.1088\n",
      "Epoch 96/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1325 - accuracy: 0.1036 - val_loss: 1.4858 - val_accuracy: 0.0731\n",
      "Epoch 97/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1334 - accuracy: 0.1018 - val_loss: 1.6396 - val_accuracy: 0.0974\n",
      "Epoch 98/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1285 - accuracy: 0.0997 - val_loss: 1.8583 - val_accuracy: 0.0372\n",
      "Epoch 99/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1252 - accuracy: 0.1020 - val_loss: 1.5913 - val_accuracy: 0.1154\n",
      "Epoch 100/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1288 - accuracy: 0.1016 - val_loss: 1.8061 - val_accuracy: 0.1000\n",
      "Epoch 101/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1273 - accuracy: 0.1011 - val_loss: 2.3202 - val_accuracy: 0.0079\n",
      "Epoch 102/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1178 - accuracy: 0.0997 - val_loss: 1.4704 - val_accuracy: 0.1513\n",
      "Epoch 103/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.1111 - accuracy: 0.1027 - val_loss: 1.5272 - val_accuracy: 0.1118\n",
      "Epoch 104/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1126 - accuracy: 0.1017 - val_loss: 1.6085 - val_accuracy: 0.0160\n",
      "Epoch 105/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1044 - accuracy: 0.1010 - val_loss: 2.0212 - val_accuracy: 0.0479\n",
      "Epoch 106/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.1048 - accuracy: 0.1025 - val_loss: 1.6155 - val_accuracy: 0.1259\n",
      "Epoch 107/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0931 - accuracy: 0.1027 - val_loss: 1.5498 - val_accuracy: 0.0706\n",
      "Epoch 108/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.0970 - accuracy: 0.1021 - val_loss: 1.6401 - val_accuracy: 0.0193\n",
      "Epoch 109/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0982 - accuracy: 0.1012 - val_loss: 1.5389 - val_accuracy: 0.1464\n",
      "Epoch 110/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0909 - accuracy: 0.1031 - val_loss: 1.7095 - val_accuracy: 0.2259\n",
      "Epoch 111/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0833 - accuracy: 0.1028 - val_loss: 1.4635 - val_accuracy: 0.0558\n",
      "Epoch 112/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0792 - accuracy: 0.1004 - val_loss: 1.7945 - val_accuracy: 0.0273\n",
      "Epoch 113/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0800 - accuracy: 0.1015 - val_loss: 1.5701 - val_accuracy: 0.1218\n",
      "Epoch 114/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0762 - accuracy: 0.1001 - val_loss: 1.7300 - val_accuracy: 0.0727\n",
      "Epoch 115/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.0624 - accuracy: 0.1009 - val_loss: 1.4727 - val_accuracy: 0.1249\n",
      "Epoch 116/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.0623 - accuracy: 0.1020 - val_loss: 1.8143 - val_accuracy: 0.0971\n",
      "Epoch 117/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0635 - accuracy: 0.1045 - val_loss: 1.4884 - val_accuracy: 0.0932\n",
      "Epoch 118/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0578 - accuracy: 0.1022 - val_loss: 1.5715 - val_accuracy: 0.0712\n",
      "Epoch 119/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0582 - accuracy: 0.1001 - val_loss: 1.7104 - val_accuracy: 0.0133\n",
      "Epoch 120/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0475 - accuracy: 0.1004 - val_loss: 1.7582 - val_accuracy: 0.1741\n",
      "Epoch 121/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0524 - accuracy: 0.1014 - val_loss: 1.6953 - val_accuracy: 0.0593\n",
      "Epoch 122/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0421 - accuracy: 0.1030 - val_loss: 1.7063 - val_accuracy: 0.1037\n",
      "Epoch 123/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0464 - accuracy: 0.1018 - val_loss: 1.6868 - val_accuracy: 0.0479\n",
      "Epoch 124/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0424 - accuracy: 0.1010 - val_loss: 2.1191 - val_accuracy: 0.0178\n",
      "Epoch 125/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0347 - accuracy: 0.1021 - val_loss: 1.8290 - val_accuracy: 0.0596\n",
      "Epoch 126/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0329 - accuracy: 0.1045 - val_loss: 1.5518 - val_accuracy: 0.1571\n",
      "Epoch 127/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0296 - accuracy: 0.1022 - val_loss: 2.3202 - val_accuracy: 0.1590\n",
      "Epoch 128/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0353 - accuracy: 0.1027 - val_loss: 1.7764 - val_accuracy: 0.0159\n",
      "Epoch 129/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0222 - accuracy: 0.1021 - val_loss: 1.6631 - val_accuracy: 0.0554\n",
      "Epoch 130/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.0154 - accuracy: 0.1023 - val_loss: 1.6512 - val_accuracy: 0.1185\n",
      "Epoch 131/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0122 - accuracy: 0.1026 - val_loss: 1.7201 - val_accuracy: 0.0671\n",
      "Epoch 132/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0143 - accuracy: 0.1040 - val_loss: 1.6772 - val_accuracy: 0.0433\n",
      "Epoch 133/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0090 - accuracy: 0.1031 - val_loss: 1.7164 - val_accuracy: 0.0469\n",
      "Epoch 134/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0085 - accuracy: 0.1014 - val_loss: 1.5797 - val_accuracy: 0.2003\n",
      "Epoch 135/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0036 - accuracy: 0.1037 - val_loss: 1.6277 - val_accuracy: 0.0659\n",
      "Epoch 136/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9973 - accuracy: 0.1018 - val_loss: 1.9708 - val_accuracy: 0.0370\n",
      "Epoch 137/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.9998 - accuracy: 0.1011 - val_loss: 1.7005 - val_accuracy: 0.0317\n",
      "Epoch 138/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 1.0003 - accuracy: 0.1013 - val_loss: 1.7678 - val_accuracy: 0.1022\n",
      "Epoch 139/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9855 - accuracy: 0.1024 - val_loss: 1.5488 - val_accuracy: 0.0360\n",
      "Epoch 140/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9925 - accuracy: 0.1008 - val_loss: 1.7185 - val_accuracy: 0.0549\n",
      "Epoch 141/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9920 - accuracy: 0.1015 - val_loss: 2.4627 - val_accuracy: 0.0192\n",
      "Epoch 142/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9841 - accuracy: 0.1035 - val_loss: 1.5739 - val_accuracy: 0.1925\n",
      "Epoch 143/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9798 - accuracy: 0.1024 - val_loss: 1.6743 - val_accuracy: 0.0429\n",
      "Epoch 144/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9768 - accuracy: 0.1031 - val_loss: 1.5664 - val_accuracy: 0.0765\n",
      "Epoch 145/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9761 - accuracy: 0.1025 - val_loss: 1.5079 - val_accuracy: 0.0396\n",
      "Epoch 146/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9740 - accuracy: 0.1012 - val_loss: 1.6537 - val_accuracy: 0.0470\n",
      "Epoch 147/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9655 - accuracy: 0.1005 - val_loss: 1.7723 - val_accuracy: 0.1314\n",
      "Epoch 148/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9667 - accuracy: 0.1029 - val_loss: 1.8586 - val_accuracy: 0.0512\n",
      "Epoch 149/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9708 - accuracy: 0.1011 - val_loss: 1.6492 - val_accuracy: 0.1621\n",
      "Epoch 150/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9633 - accuracy: 0.1031 - val_loss: 1.8202 - val_accuracy: 0.0449\n",
      "Epoch 151/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9644 - accuracy: 0.1031 - val_loss: 1.9291 - val_accuracy: 0.1067\n",
      "Epoch 152/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9561 - accuracy: 0.1025 - val_loss: 1.7464 - val_accuracy: 0.0425\n",
      "Epoch 153/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9484 - accuracy: 0.1017 - val_loss: 1.7286 - val_accuracy: 0.0161\n",
      "Epoch 154/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9540 - accuracy: 0.1013 - val_loss: 1.5905 - val_accuracy: 0.0499\n",
      "Epoch 155/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9537 - accuracy: 0.1031 - val_loss: 1.6551 - val_accuracy: 0.0335\n",
      "Epoch 156/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9461 - accuracy: 0.1015 - val_loss: 1.7162 - val_accuracy: 0.0692\n",
      "Epoch 157/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9368 - accuracy: 0.1029 - val_loss: 1.4704 - val_accuracy: 0.0913\n",
      "Epoch 158/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9421 - accuracy: 0.1018 - val_loss: 1.7146 - val_accuracy: 0.0161\n",
      "Epoch 159/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9369 - accuracy: 0.1013 - val_loss: 1.7758 - val_accuracy: 0.0976\n",
      "Epoch 160/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9400 - accuracy: 0.1032 - val_loss: 1.7643 - val_accuracy: 0.0803\n",
      "Epoch 161/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9303 - accuracy: 0.1029 - val_loss: 1.7359 - val_accuracy: 0.0348\n",
      "Epoch 162/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9278 - accuracy: 0.1013 - val_loss: 1.4281 - val_accuracy: 0.1315\n",
      "INFO:tensorflow:Assets written to: thankyoualls/assets\n",
      "Epoch 163/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9193 - accuracy: 0.1045 - val_loss: 2.3417 - val_accuracy: 0.1249\n",
      "Epoch 164/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9227 - accuracy: 0.1031 - val_loss: 1.5767 - val_accuracy: 0.0959\n",
      "Epoch 165/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9189 - accuracy: 0.1038 - val_loss: 1.5416 - val_accuracy: 0.0137\n",
      "Epoch 166/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9197 - accuracy: 0.1028 - val_loss: 1.9015 - val_accuracy: 0.0380\n",
      "Epoch 167/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9144 - accuracy: 0.1032 - val_loss: 1.5525 - val_accuracy: 0.0419\n",
      "Epoch 168/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9072 - accuracy: 0.1024 - val_loss: 1.5829 - val_accuracy: 0.1503\n",
      "Epoch 169/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9124 - accuracy: 0.1023 - val_loss: 1.6776 - val_accuracy: 0.2710\n",
      "Epoch 170/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9124 - accuracy: 0.1037 - val_loss: 1.5753 - val_accuracy: 0.0962\n",
      "Epoch 171/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.1028 - val_loss: 1.7701 - val_accuracy: 0.1221\n",
      "Epoch 172/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9100 - accuracy: 0.1031 - val_loss: 1.6741 - val_accuracy: 0.0579\n",
      "Epoch 173/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9004 - accuracy: 0.1024 - val_loss: 1.6633 - val_accuracy: 0.2176\n",
      "Epoch 174/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8979 - accuracy: 0.1031 - val_loss: 1.8552 - val_accuracy: 0.1899\n",
      "Epoch 175/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8959 - accuracy: 0.1017 - val_loss: 1.6506 - val_accuracy: 0.0825\n",
      "Epoch 176/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8903 - accuracy: 0.1028 - val_loss: 1.7727 - val_accuracy: 0.0229\n",
      "Epoch 177/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8936 - accuracy: 0.1028 - val_loss: 1.6272 - val_accuracy: 0.0782\n",
      "Epoch 178/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8870 - accuracy: 0.1023 - val_loss: 1.7050 - val_accuracy: 0.0342\n",
      "Epoch 179/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8887 - accuracy: 0.1022 - val_loss: 2.1808 - val_accuracy: 0.0140\n",
      "Epoch 180/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8888 - accuracy: 0.1045 - val_loss: 1.7765 - val_accuracy: 0.0412\n",
      "Epoch 181/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8781 - accuracy: 0.1036 - val_loss: 1.8029 - val_accuracy: 0.0762\n",
      "Epoch 182/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8774 - accuracy: 0.1036 - val_loss: 1.7037 - val_accuracy: 0.0906\n",
      "Epoch 183/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8816 - accuracy: 0.1007 - val_loss: 1.7484 - val_accuracy: 0.0404\n",
      "Epoch 184/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8701 - accuracy: 0.1033 - val_loss: 1.6124 - val_accuracy: 0.0723\n",
      "Epoch 185/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8725 - accuracy: 0.1023 - val_loss: 1.7469 - val_accuracy: 0.0261\n",
      "Epoch 186/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8716 - accuracy: 0.1023 - val_loss: 1.6840 - val_accuracy: 0.0484\n",
      "Epoch 187/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8677 - accuracy: 0.1031 - val_loss: 1.7836 - val_accuracy: 0.1945\n",
      "Epoch 188/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8667 - accuracy: 0.1026 - val_loss: 1.7633 - val_accuracy: 0.1002\n",
      "Epoch 189/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8675 - accuracy: 0.1031 - val_loss: 1.7209 - val_accuracy: 0.0725\n",
      "Epoch 190/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8609 - accuracy: 0.1023 - val_loss: 1.7011 - val_accuracy: 0.1607\n",
      "Epoch 191/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8600 - accuracy: 0.1033 - val_loss: 1.7269 - val_accuracy: 0.0670\n",
      "Epoch 192/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8517 - accuracy: 0.1021 - val_loss: 1.9185 - val_accuracy: 0.3126\n",
      "Epoch 193/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8512 - accuracy: 0.1035 - val_loss: 1.5596 - val_accuracy: 0.1078\n",
      "Epoch 194/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8530 - accuracy: 0.1030 - val_loss: 1.9547 - val_accuracy: 0.0605\n",
      "Epoch 195/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8515 - accuracy: 0.1032 - val_loss: 2.0182 - val_accuracy: 0.0506\n",
      "Epoch 196/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8429 - accuracy: 0.1020 - val_loss: 1.7270 - val_accuracy: 0.0900\n",
      "Epoch 197/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8384 - accuracy: 0.1045 - val_loss: 1.7751 - val_accuracy: 0.0476\n",
      "Epoch 198/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8510 - accuracy: 0.1045 - val_loss: 1.8184 - val_accuracy: 0.0672\n",
      "Epoch 199/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8420 - accuracy: 0.1031 - val_loss: 1.9106 - val_accuracy: 0.0409\n",
      "Epoch 200/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8401 - accuracy: 0.1028 - val_loss: 1.7873 - val_accuracy: 0.1423\n",
      "Epoch 201/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8427 - accuracy: 0.1036 - val_loss: 1.6980 - val_accuracy: 0.0406\n",
      "Epoch 202/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8417 - accuracy: 0.1015 - val_loss: 1.6634 - val_accuracy: 0.1158\n",
      "Epoch 203/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8321 - accuracy: 0.1034 - val_loss: 1.5107 - val_accuracy: 0.1560\n",
      "Epoch 204/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8296 - accuracy: 0.1018 - val_loss: 1.4590 - val_accuracy: 0.0830\n",
      "Epoch 205/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8270 - accuracy: 0.1020 - val_loss: 1.8098 - val_accuracy: 0.0888\n",
      "Epoch 206/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8244 - accuracy: 0.1031 - val_loss: 1.6622 - val_accuracy: 0.0416\n",
      "Epoch 207/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8321 - accuracy: 0.1012 - val_loss: 1.8135 - val_accuracy: 0.0683\n",
      "Epoch 208/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8222 - accuracy: 0.1050 - val_loss: 1.8965 - val_accuracy: 0.0292\n",
      "Epoch 209/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8180 - accuracy: 0.1028 - val_loss: 1.7033 - val_accuracy: 0.0604\n",
      "Epoch 210/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8209 - accuracy: 0.1044 - val_loss: 1.7148 - val_accuracy: 0.0375\n",
      "Epoch 211/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8147 - accuracy: 0.1039 - val_loss: 2.0309 - val_accuracy: 0.3708\n",
      "Epoch 212/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8181 - accuracy: 0.1018 - val_loss: 1.5306 - val_accuracy: 0.0963\n",
      "Epoch 213/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8079 - accuracy: 0.1028 - val_loss: 2.1277 - val_accuracy: 0.0993\n",
      "Epoch 214/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.8056 - accuracy: 0.1027 - val_loss: 1.7081 - val_accuracy: 0.0519\n",
      "Epoch 215/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8105 - accuracy: 0.1056 - val_loss: 1.6618 - val_accuracy: 0.0619\n",
      "Epoch 216/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7955 - accuracy: 0.1024 - val_loss: 1.5940 - val_accuracy: 0.0313\n",
      "Epoch 217/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8106 - accuracy: 0.1012 - val_loss: 1.7416 - val_accuracy: 0.1054\n",
      "Epoch 218/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.8015 - accuracy: 0.1050 - val_loss: 1.9783 - val_accuracy: 0.0593\n",
      "Epoch 219/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7946 - accuracy: 0.1017 - val_loss: 2.3627 - val_accuracy: 0.0130\n",
      "Epoch 220/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.8051 - accuracy: 0.1035 - val_loss: 1.7202 - val_accuracy: 0.0844\n",
      "Epoch 221/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7991 - accuracy: 0.1042 - val_loss: 1.6426 - val_accuracy: 0.1188\n",
      "Epoch 222/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7908 - accuracy: 0.1029 - val_loss: 1.7554 - val_accuracy: 0.0512\n",
      "Epoch 223/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7901 - accuracy: 0.1041 - val_loss: 1.6723 - val_accuracy: 0.2270\n",
      "Epoch 224/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7879 - accuracy: 0.1045 - val_loss: 1.7645 - val_accuracy: 0.0999\n",
      "Epoch 225/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7913 - accuracy: 0.1016 - val_loss: 2.1238 - val_accuracy: 0.4351\n",
      "Epoch 226/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7870 - accuracy: 0.1034 - val_loss: 1.6268 - val_accuracy: 0.0969\n",
      "Epoch 227/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7827 - accuracy: 0.1032 - val_loss: 2.0004 - val_accuracy: 0.0308\n",
      "Epoch 228/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7865 - accuracy: 0.1032 - val_loss: 1.8332 - val_accuracy: 0.0185\n",
      "Epoch 229/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7812 - accuracy: 0.1028 - val_loss: 1.7946 - val_accuracy: 0.0229\n",
      "Epoch 230/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7839 - accuracy: 0.1019 - val_loss: 1.7287 - val_accuracy: 0.2238\n",
      "Epoch 231/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.7820 - accuracy: 0.1029 - val_loss: 1.9695 - val_accuracy: 0.1568\n",
      "Epoch 232/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7784 - accuracy: 0.1062 - val_loss: 1.9203 - val_accuracy: 0.0113\n",
      "Epoch 233/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7752 - accuracy: 0.1029 - val_loss: 1.6724 - val_accuracy: 0.0887\n",
      "Epoch 234/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7738 - accuracy: 0.1037 - val_loss: 1.7409 - val_accuracy: 0.1560\n",
      "Epoch 235/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7717 - accuracy: 0.1037 - val_loss: 1.7914 - val_accuracy: 0.0187\n",
      "Epoch 236/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7840 - accuracy: 0.1032 - val_loss: 1.8472 - val_accuracy: 0.0450\n",
      "Epoch 237/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7618 - accuracy: 0.1008 - val_loss: 1.7765 - val_accuracy: 0.1313\n",
      "Epoch 238/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7583 - accuracy: 0.1034 - val_loss: 1.5740 - val_accuracy: 0.0655\n",
      "Epoch 239/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7587 - accuracy: 0.1044 - val_loss: 2.0574 - val_accuracy: 0.0386\n",
      "Epoch 240/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7629 - accuracy: 0.1032 - val_loss: 1.7744 - val_accuracy: 0.1761\n",
      "Epoch 241/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7606 - accuracy: 0.1042 - val_loss: 1.8196 - val_accuracy: 0.0610\n",
      "Epoch 242/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7536 - accuracy: 0.1022 - val_loss: 1.7433 - val_accuracy: 0.0514\n",
      "Epoch 243/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7581 - accuracy: 0.1039 - val_loss: 2.2037 - val_accuracy: 0.0468\n",
      "Epoch 244/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7492 - accuracy: 0.1022 - val_loss: 1.7795 - val_accuracy: 0.0474\n",
      "Epoch 245/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7406 - accuracy: 0.1036 - val_loss: 1.6898 - val_accuracy: 0.0359\n",
      "Epoch 246/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7521 - accuracy: 0.1030 - val_loss: 1.6265 - val_accuracy: 0.0643\n",
      "Epoch 247/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7456 - accuracy: 0.1029 - val_loss: 1.7472 - val_accuracy: 0.1113\n",
      "Epoch 248/1000\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.7514 - accuracy: 0.1022 - val_loss: 1.9101 - val_accuracy: 0.0204\n",
      "Epoch 249/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7433 - accuracy: 0.1018 - val_loss: 1.7793 - val_accuracy: 0.1267\n",
      "Epoch 250/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7461 - accuracy: 0.1039 - val_loss: 1.6008 - val_accuracy: 0.1067\n",
      "Epoch 251/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7482 - accuracy: 0.1028 - val_loss: 1.6692 - val_accuracy: 0.1553\n",
      "Epoch 252/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7353 - accuracy: 0.1028 - val_loss: 1.7067 - val_accuracy: 0.0464\n",
      "Epoch 253/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7344 - accuracy: 0.1042 - val_loss: 1.8885 - val_accuracy: 0.1610\n",
      "Epoch 254/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7455 - accuracy: 0.1033 - val_loss: 2.0664 - val_accuracy: 0.0388\n",
      "Epoch 255/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7329 - accuracy: 0.1028 - val_loss: 1.5971 - val_accuracy: 0.0815\n",
      "Epoch 256/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7323 - accuracy: 0.1036 - val_loss: 1.5689 - val_accuracy: 0.1539\n",
      "Epoch 257/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7320 - accuracy: 0.1025 - val_loss: 1.8273 - val_accuracy: 0.0495\n",
      "Epoch 258/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7329 - accuracy: 0.1033 - val_loss: 1.5948 - val_accuracy: 0.1479\n",
      "Epoch 259/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7287 - accuracy: 0.1023 - val_loss: 1.6397 - val_accuracy: 0.2047\n",
      "Epoch 260/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7252 - accuracy: 0.1039 - val_loss: 1.5760 - val_accuracy: 0.0600\n",
      "Epoch 261/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7222 - accuracy: 0.1019 - val_loss: 1.5570 - val_accuracy: 0.1815\n",
      "Epoch 262/1000\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.7262 - accuracy: 0.1037 - val_loss: 1.5160 - val_accuracy: 0.0700\n"
     ]
    }
   ],
   "source": [
    "# 문제 3-4: ModelCheckpoint와 EarlyStopping 콜백 함수를 적용하여 모델 학습을 진행합니다.\n",
    "check_point_cb = callbacks.ModelCheckpoint('thankyoualls', save_best_only=True)\n",
    "early_stopping_cb = callbacks.EarlyStopping(patience=100, monitor='val_loss',\n",
    "                                  restore_best_weights=True)\n",
    "history = model.fit(x_train, y_train, epochs=1000,batch_size = 1024,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[check_point_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "995478ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    history_dict = history.history\n",
    "\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(epochs, loss, 'b-', label='train_loss')\n",
    "    ax1.plot(epochs, val_loss, 'r-', label='val_loss')\n",
    "    ax1.set_title('Train and Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "\n",
    "    accuracy = history_dict['accuracy']\n",
    "    val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.plot(epochs, accuracy, 'b-', label='train_accuracy')\n",
    "    ax2.plot(epochs, val_accuracy, 'r-', label='val_accuracy')\n",
    "    ax2.set_title('Train and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4b6de8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4278 - accuracy: 0.1392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4277629852294922, 0.13920000195503235]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 데이터셋을 이용해 모델을 평가합니다.\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab0baa",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "1) ValueError: Shapes (32, 10) and (32, 1) are incompatible 에러발생\n",
    "데이터 셋의 문제가 아니라 \n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "loss 파트를 이렇게 바꿈으로 해결.\n",
    "\n",
    "\n",
    "2) 돌아가나 결과값은 아주 처참하다.. https://www.kaggle.com/code/nataliakhol/cifar10-transfer-learning\n",
    "캐글에서 잘된 결과를 보면 정확도가 90%가 넘는데.. 코드가 이해되지 않는다. 한참 파봐야할듯하다.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
