{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f5d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73010e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# keras.datasets 안에 boston_housing 데이터셋을 로드합니다.\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
    "\n",
    "# 데이터셋의 크기를 확인합니다.\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe4f3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c307bfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18.0846,   0.    ,  18.1   ,   0.    ,   0.679 ,   6.434 ,\n",
       "       100.    ,   1.8347,  24.    , 666.    ,  20.2   ,  27.25  ,\n",
       "        29.05  ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37990557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0]\n",
    "\n",
    "# # array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
    "# #         91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
    "# #         18.72   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "578fc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_mean\n",
    "\n",
    "# # array([3.74511057e+00, 1.14801980e+01, 1.11044307e+01, 6.18811881e-02,\n",
    "#        5.57355941e-01, 6.26708168e+00, 6.90106436e+01, 3.74027079e+00,\n",
    "#        9.44059406e+00, 4.05898515e+02, 1.84759901e+01, 3.54783168e+02,\n",
    "#        1.27408168e+01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bb12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_std\n",
    "\n",
    "# # array([9.22929073e+00, 2.37382770e+01, 6.80287253e+00, 2.40939633e-01,\n",
    "#        1.17147847e-01, 7.08908627e-01, 2.79060634e+01, 2.02770050e+00,\n",
    "#        8.68758849e+00, 1.66168506e+02, 2.19765689e+00, 9.39946015e+01,\n",
    "#        7.24556085e+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcfc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data - train_data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e882137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1-1: 데이터셋의 전처리를 위해 표준화 작업을 수행합니다.\n",
    "# 먼저 입력 데이터의 각 특성의 평균을 뺍니다.\n",
    "\n",
    "train_data_mean = train_data.mean(axis=0) \n",
    "train_data_std = train_data.std(axis=0)\n",
    "train_data = train_data - train_data_mean\n",
    "\n",
    "        \n",
    "# 평균을 뺀 입력 데이터에서 표준편차를 나눕니다.\n",
    "# 데이터 특성의 중앙이 0에 가깝게 만들고, 표준편차가 1이 되게 만듭니다.\n",
    "train_data = train_data/train_data_std\n",
    "\n",
    "# 테스트 데이터셋도 마찬가지로 평균을 빼고, 표준편차로 나눕니다.\n",
    "test_data_mean = test_data.mean(axis=0) \n",
    "test_data_std = test_data.std(axis=0)\n",
    "test_data = test_data - test_data_mean\n",
    "test_data = test_data/test_data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c202ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444d607",
   "metadata": {},
   "source": [
    "모델 구성 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f506e17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 5,056\n",
      "Trainable params: 5,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 문제 1-2: 주택 가격 예측을 위한 딥러닝 모델 구성 및 컴파일합니다.\n",
    "# input_shape은 (train_data.shape[1], )으로 구성합니다.\n",
    "# 회귀(예측)을 위한 모델은 loss와 metrics를 mse로 사용합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=13,))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(loss='mse', metrics = ['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebff715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 568.7686 - mae: 21.9975 - val_loss: 583.3625 - val_mae: 22.3575\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 537.7945 - mae: 21.3061 - val_loss: 544.8287 - val_mae: 21.5017\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 495.8522 - mae: 20.3458 - val_loss: 497.1448 - val_mae: 20.4024\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 445.0664 - mae: 19.1279 - val_loss: 440.5308 - val_mae: 19.0383\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 388.5557 - mae: 17.6907 - val_loss: 379.4780 - val_mae: 17.4819\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 327.4751 - mae: 16.0149 - val_loss: 316.8747 - val_mae: 15.7673\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 267.7076 - mae: 14.2321 - val_loss: 256.5204 - val_mae: 13.9818\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 210.7173 - mae: 12.2865 - val_loss: 201.0649 - val_mae: 12.2112\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 161.8656 - mae: 10.4169 - val_loss: 154.8534 - val_mae: 10.6415\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 122.3548 - mae: 8.8064 - val_loss: 117.7663 - val_mae: 9.2041\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 92.8166 - mae: 7.4705 - val_loss: 90.4029 - val_mae: 7.9171\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 72.2691 - mae: 6.4844 - val_loss: 72.0907 - val_mae: 6.9150\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 58.5229 - mae: 5.7632 - val_loss: 59.0840 - val_mae: 6.1170\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 49.1627 - mae: 5.1373 - val_loss: 50.4698 - val_mae: 5.5590\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 42.5486 - mae: 4.7001 - val_loss: 43.9064 - val_mae: 5.1140\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 37.6036 - mae: 4.3443 - val_loss: 39.0105 - val_mae: 4.8162\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 34.2331 - mae: 4.1152 - val_loss: 35.8074 - val_mae: 4.6266\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 31.7437 - mae: 3.9300 - val_loss: 33.4728 - val_mae: 4.5027\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 30.2463 - mae: 3.8305 - val_loss: 31.9293 - val_mae: 4.4028\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 28.8696 - mae: 3.7373 - val_loss: 30.4758 - val_mae: 4.2953\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 27.8190 - mae: 3.6907 - val_loss: 29.5208 - val_mae: 4.2269\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 26.9137 - mae: 3.6283 - val_loss: 28.5099 - val_mae: 4.1369\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 26.1040 - mae: 3.5499 - val_loss: 27.3693 - val_mae: 4.0458\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 25.3690 - mae: 3.5155 - val_loss: 26.7546 - val_mae: 4.0052\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 24.6844 - mae: 3.4817 - val_loss: 26.0126 - val_mae: 3.9356\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 24.0947 - mae: 3.4430 - val_loss: 25.5963 - val_mae: 3.9026\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 23.5323 - mae: 3.4179 - val_loss: 24.9577 - val_mae: 3.8463\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 22.9235 - mae: 3.3631 - val_loss: 24.3902 - val_mae: 3.8003\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 22.3763 - mae: 3.3382 - val_loss: 23.9804 - val_mae: 3.7591\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 21.8445 - mae: 3.3019 - val_loss: 23.5749 - val_mae: 3.7203\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 21.3925 - mae: 3.2865 - val_loss: 23.2868 - val_mae: 3.6761\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 20.8732 - mae: 3.2214 - val_loss: 23.0679 - val_mae: 3.6495\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 20.4106 - mae: 3.2009 - val_loss: 22.7693 - val_mae: 3.6416\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 20.1470 - mae: 3.1738 - val_loss: 22.2710 - val_mae: 3.6076\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 19.5476 - mae: 3.1381 - val_loss: 22.0089 - val_mae: 3.5800\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 19.0083 - mae: 3.1067 - val_loss: 21.9828 - val_mae: 3.5496\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 18.7072 - mae: 3.0627 - val_loss: 21.3670 - val_mae: 3.5116\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 18.3425 - mae: 3.0604 - val_loss: 21.4989 - val_mae: 3.4949\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 17.9135 - mae: 2.9991 - val_loss: 21.7416 - val_mae: 3.4949\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 17.6694 - mae: 2.9824 - val_loss: 21.0429 - val_mae: 3.4478\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 17.1868 - mae: 2.9425 - val_loss: 20.7137 - val_mae: 3.4215\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 16.8076 - mae: 2.9039 - val_loss: 20.4678 - val_mae: 3.4036\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 16.4759 - mae: 2.8914 - val_loss: 20.5452 - val_mae: 3.3821\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 16.0934 - mae: 2.8501 - val_loss: 20.7263 - val_mae: 3.3719\n",
      "Epoch 45/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 15.7864 - mae: 2.8126 - val_loss: 20.1453 - val_mae: 3.3304\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 15.4131 - mae: 2.7993 - val_loss: 19.9699 - val_mae: 3.3074\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 15.1244 - mae: 2.7572 - val_loss: 19.7391 - val_mae: 3.2816\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 14.8290 - mae: 2.7424 - val_loss: 19.6404 - val_mae: 3.2672\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 14.4540 - mae: 2.7014 - val_loss: 19.6210 - val_mae: 3.2458\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 14.1692 - mae: 2.6648 - val_loss: 19.4644 - val_mae: 3.2257\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 13.9799 - mae: 2.6574 - val_loss: 19.4455 - val_mae: 3.2044\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 13.7223 - mae: 2.6217 - val_loss: 19.3545 - val_mae: 3.1844\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 13.3919 - mae: 2.5904 - val_loss: 19.4036 - val_mae: 3.1905\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 13.2015 - mae: 2.5608 - val_loss: 19.3318 - val_mae: 3.1692\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 12.8967 - mae: 2.5256 - val_loss: 19.1495 - val_mae: 3.1339\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 12.7374 - mae: 2.5261 - val_loss: 19.1582 - val_mae: 3.1291\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 12.5035 - mae: 2.5035 - val_loss: 19.2871 - val_mae: 3.1432\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 12.3583 - mae: 2.4496 - val_loss: 19.3345 - val_mae: 3.1480\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 12.1453 - mae: 2.4341 - val_loss: 19.1805 - val_mae: 3.1138\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 11.9059 - mae: 2.4086 - val_loss: 19.1705 - val_mae: 3.0927\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 11.8047 - mae: 2.4087 - val_loss: 19.1560 - val_mae: 3.0955\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 11.6101 - mae: 2.3868 - val_loss: 18.9395 - val_mae: 3.0701\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 11.5094 - mae: 2.3737 - val_loss: 19.1222 - val_mae: 3.0783\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 11.1825 - mae: 2.3407 - val_loss: 19.2350 - val_mae: 3.1066\n",
      "Epoch 65/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 11.1689 - mae: 2.3443 - val_loss: 19.1821 - val_mae: 3.0691\n",
      "Epoch 66/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 11.0486 - mae: 2.3244 - val_loss: 19.0407 - val_mae: 3.0538\n",
      "Epoch 67/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.9062 - mae: 2.3119 - val_loss: 19.0317 - val_mae: 3.0423\n",
      "Epoch 68/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.7735 - mae: 2.3074 - val_loss: 19.1734 - val_mae: 3.0575\n",
      "Epoch 69/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.6890 - mae: 2.2840 - val_loss: 19.1300 - val_mae: 3.0342\n",
      "Epoch 70/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.5583 - mae: 2.2855 - val_loss: 19.1697 - val_mae: 3.0544\n",
      "Epoch 71/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.4580 - mae: 2.2706 - val_loss: 19.1005 - val_mae: 3.0115\n",
      "Epoch 72/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.3970 - mae: 2.2695 - val_loss: 19.1475 - val_mae: 3.0244\n",
      "Epoch 73/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.2884 - mae: 2.2670 - val_loss: 19.1890 - val_mae: 3.0366\n",
      "Epoch 74/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.1708 - mae: 2.2418 - val_loss: 19.4462 - val_mae: 3.0646\n",
      "Epoch 75/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.2189 - mae: 2.2324 - val_loss: 19.2735 - val_mae: 3.0364\n",
      "Epoch 76/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.0852 - mae: 2.2191 - val_loss: 19.2815 - val_mae: 3.0220\n",
      "Epoch 77/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 10.0058 - mae: 2.2139 - val_loss: 19.3606 - val_mae: 3.0272\n",
      "Epoch 78/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.9232 - mae: 2.2006 - val_loss: 19.2612 - val_mae: 3.0147\n",
      "Epoch 79/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.8636 - mae: 2.2046 - val_loss: 19.1559 - val_mae: 3.0018\n",
      "Epoch 80/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.8307 - mae: 2.2081 - val_loss: 19.2130 - val_mae: 2.9971\n",
      "Epoch 81/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.7967 - mae: 2.1882 - val_loss: 19.1660 - val_mae: 2.9882\n",
      "Epoch 82/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.7433 - mae: 2.1906 - val_loss: 19.1614 - val_mae: 2.9817\n",
      "Epoch 83/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.7159 - mae: 2.1781 - val_loss: 19.2549 - val_mae: 2.9901\n",
      "Epoch 84/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.5769 - mae: 2.1651 - val_loss: 19.3142 - val_mae: 2.9944\n",
      "Epoch 85/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.5305 - mae: 2.1598 - val_loss: 19.4617 - val_mae: 3.0359\n",
      "Epoch 86/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.5585 - mae: 2.1584 - val_loss: 19.2290 - val_mae: 2.9624\n",
      "Epoch 87/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3364 - mae: 2.1536 - val_loss: 19.2847 - val_mae: 2.9772\n",
      "Epoch 88/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3754 - mae: 2.1675 - val_loss: 19.3765 - val_mae: 3.0101\n",
      "Epoch 89/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3550 - mae: 2.1580 - val_loss: 19.2348 - val_mae: 2.9767\n",
      "Epoch 90/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3101 - mae: 2.1387 - val_loss: 19.1584 - val_mae: 2.9668\n",
      "Epoch 91/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.3181 - mae: 2.1490 - val_loss: 19.0847 - val_mae: 2.9405\n",
      "Epoch 92/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.2197 - mae: 2.1347 - val_loss: 19.1612 - val_mae: 2.9452\n",
      "Epoch 93/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.1940 - mae: 2.1270 - val_loss: 19.1446 - val_mae: 2.9304\n",
      "Epoch 94/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.1076 - mae: 2.1428 - val_loss: 19.2114 - val_mae: 2.9396\n",
      "Epoch 95/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.1003 - mae: 2.1330 - val_loss: 19.3961 - val_mae: 2.9702\n",
      "Epoch 96/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.9818 - mae: 2.0853 - val_loss: 19.3830 - val_mae: 2.9801\n",
      "Epoch 97/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.9718 - mae: 2.1192 - val_loss: 19.2292 - val_mae: 2.9641\n",
      "Epoch 98/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 9.0038 - mae: 2.1043 - val_loss: 19.1534 - val_mae: 2.9342\n",
      "Epoch 99/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.9600 - mae: 2.1113 - val_loss: 19.1627 - val_mae: 2.9291\n",
      "Epoch 100/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.9270 - mae: 2.1039 - val_loss: 19.1362 - val_mae: 2.9355\n",
      "Epoch 101/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.8883 - mae: 2.1075 - val_loss: 19.2686 - val_mae: 2.9454\n",
      "Epoch 102/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.8505 - mae: 2.0987 - val_loss: 19.3457 - val_mae: 2.9540\n",
      "Epoch 103/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.8473 - mae: 2.0985 - val_loss: 19.2873 - val_mae: 2.9441\n",
      "Epoch 104/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.7658 - mae: 2.0874 - val_loss: 19.2615 - val_mae: 2.9184\n",
      "Epoch 105/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.7812 - mae: 2.0851 - val_loss: 19.3887 - val_mae: 2.9376\n",
      "Epoch 106/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.7183 - mae: 2.0782 - val_loss: 19.2557 - val_mae: 2.9361\n",
      "Epoch 107/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.7216 - mae: 2.0843 - val_loss: 19.2461 - val_mae: 2.9351\n",
      "Epoch 108/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.6601 - mae: 2.0630 - val_loss: 19.0191 - val_mae: 2.9101\n",
      "Epoch 109/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.6410 - mae: 2.0737 - val_loss: 18.9955 - val_mae: 2.8727\n",
      "Epoch 110/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.5810 - mae: 2.0690 - val_loss: 19.1053 - val_mae: 2.9176\n",
      "Epoch 111/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.5872 - mae: 2.0728 - val_loss: 19.1492 - val_mae: 2.9253\n",
      "Epoch 112/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.5241 - mae: 2.0392 - val_loss: 18.9015 - val_mae: 2.8810\n",
      "Epoch 113/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.5364 - mae: 2.0735 - val_loss: 18.9851 - val_mae: 2.9044\n",
      "Epoch 114/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.5629 - mae: 2.0644 - val_loss: 18.9924 - val_mae: 2.9056\n",
      "Epoch 115/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.4847 - mae: 2.0424 - val_loss: 18.9637 - val_mae: 2.8900\n",
      "Epoch 116/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.4882 - mae: 2.0702 - val_loss: 19.0651 - val_mae: 2.8973\n",
      "Epoch 117/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.4082 - mae: 2.0411 - val_loss: 18.9298 - val_mae: 2.8891\n",
      "Epoch 118/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.4390 - mae: 2.0510 - val_loss: 19.0776 - val_mae: 2.9160\n",
      "Epoch 119/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3493 - mae: 2.0345 - val_loss: 19.1367 - val_mae: 2.9028\n",
      "Epoch 120/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3613 - mae: 2.0244 - val_loss: 19.0001 - val_mae: 2.8699\n",
      "Epoch 121/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3414 - mae: 2.0301 - val_loss: 18.8727 - val_mae: 2.8861\n",
      "Epoch 122/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3398 - mae: 2.0389 - val_loss: 18.9250 - val_mae: 2.9263\n",
      "Epoch 123/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3359 - mae: 2.0389 - val_loss: 18.8408 - val_mae: 2.8747\n",
      "Epoch 124/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.3013 - mae: 2.0282 - val_loss: 18.9717 - val_mae: 2.8648\n",
      "Epoch 125/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2614 - mae: 2.0156 - val_loss: 18.7723 - val_mae: 2.8399\n",
      "Epoch 126/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2630 - mae: 2.0277 - val_loss: 18.7906 - val_mae: 2.8522\n",
      "Epoch 127/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2344 - mae: 2.0169 - val_loss: 18.6838 - val_mae: 2.8454\n",
      "Epoch 128/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.2490 - mae: 2.0257 - val_loss: 18.6716 - val_mae: 2.8580\n",
      "Epoch 129/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1674 - mae: 2.0234 - val_loss: 18.6771 - val_mae: 2.8423\n",
      "Epoch 130/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1476 - mae: 2.0207 - val_loss: 18.8221 - val_mae: 2.8781\n",
      "Epoch 131/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1511 - mae: 2.0152 - val_loss: 18.6298 - val_mae: 2.8415\n",
      "Epoch 132/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1574 - mae: 2.0207 - val_loss: 18.6735 - val_mae: 2.8493\n",
      "Epoch 133/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1194 - mae: 2.0020 - val_loss: 18.7114 - val_mae: 2.8634\n",
      "Epoch 134/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.1156 - mae: 2.0167 - val_loss: 18.5848 - val_mae: 2.8452\n",
      "Epoch 135/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0785 - mae: 1.9943 - val_loss: 18.4471 - val_mae: 2.8009\n",
      "Epoch 136/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0334 - mae: 2.0182 - val_loss: 18.7136 - val_mae: 2.8519\n",
      "Epoch 137/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0669 - mae: 2.0001 - val_loss: 18.5657 - val_mae: 2.8349\n",
      "Epoch 138/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.9711 - mae: 1.9917 - val_loss: 18.6544 - val_mae: 2.8805\n",
      "Epoch 139/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0568 - mae: 2.0000 - val_loss: 18.6965 - val_mae: 2.8922\n",
      "Epoch 140/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.9848 - mae: 2.0080 - val_loss: 18.6483 - val_mae: 2.8833\n",
      "Epoch 141/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0314 - mae: 1.9839 - val_loss: 18.5749 - val_mae: 2.8459\n",
      "Epoch 142/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 8.0052 - mae: 1.9816 - val_loss: 18.5606 - val_mae: 2.8241\n",
      "Epoch 143/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.9354 - mae: 1.9824 - val_loss: 18.8184 - val_mae: 2.8603\n",
      "Epoch 144/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.9440 - mae: 1.9927 - val_loss: 18.5893 - val_mae: 2.8640\n",
      "Epoch 145/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.9201 - mae: 1.9770 - val_loss: 18.4482 - val_mae: 2.8063\n",
      "Epoch 146/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.9034 - mae: 1.9811 - val_loss: 18.5096 - val_mae: 2.8194\n",
      "Epoch 147/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8633 - mae: 1.9909 - val_loss: 18.6783 - val_mae: 2.8648\n",
      "Epoch 148/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.9053 - mae: 1.9775 - val_loss: 18.4942 - val_mae: 2.8090\n",
      "Epoch 149/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8088 - mae: 1.9808 - val_loss: 18.5012 - val_mae: 2.8627\n",
      "Epoch 150/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8979 - mae: 1.9581 - val_loss: 18.3885 - val_mae: 2.7988\n",
      "Epoch 151/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8312 - mae: 1.9718 - val_loss: 18.2433 - val_mae: 2.7843\n",
      "Epoch 152/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8473 - mae: 1.9706 - val_loss: 18.3879 - val_mae: 2.8207\n",
      "Epoch 153/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7664 - mae: 1.9680 - val_loss: 18.4801 - val_mae: 2.8093\n",
      "Epoch 154/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8009 - mae: 1.9747 - val_loss: 18.2985 - val_mae: 2.8083\n",
      "Epoch 155/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.8200 - mae: 1.9722 - val_loss: 18.1947 - val_mae: 2.8003\n",
      "Epoch 156/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7884 - mae: 1.9685 - val_loss: 18.1242 - val_mae: 2.7734\n",
      "Epoch 157/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7241 - mae: 1.9698 - val_loss: 18.0654 - val_mae: 2.7599\n",
      "Epoch 158/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7024 - mae: 1.9728 - val_loss: 18.2932 - val_mae: 2.8153\n",
      "Epoch 159/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7448 - mae: 1.9578 - val_loss: 18.1215 - val_mae: 2.7644\n",
      "Epoch 160/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6750 - mae: 1.9682 - val_loss: 18.1540 - val_mae: 2.7885\n",
      "Epoch 161/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6872 - mae: 1.9604 - val_loss: 18.0801 - val_mae: 2.7768\n",
      "Epoch 162/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.7105 - mae: 1.9597 - val_loss: 18.2900 - val_mae: 2.8234\n",
      "Epoch 163/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6899 - mae: 1.9581 - val_loss: 18.2800 - val_mae: 2.7934\n",
      "Epoch 164/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6806 - mae: 1.9455 - val_loss: 18.2331 - val_mae: 2.7857\n",
      "Epoch 165/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6740 - mae: 1.9518 - val_loss: 18.1919 - val_mae: 2.7841\n",
      "Epoch 166/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6242 - mae: 1.9579 - val_loss: 18.2567 - val_mae: 2.8185\n",
      "Epoch 167/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6630 - mae: 1.9405 - val_loss: 18.0722 - val_mae: 2.7780\n",
      "Epoch 168/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6205 - mae: 1.9521 - val_loss: 18.1143 - val_mae: 2.7805\n",
      "Epoch 169/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6460 - mae: 1.9465 - val_loss: 18.1209 - val_mae: 2.7752\n",
      "Epoch 170/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5784 - mae: 1.9339 - val_loss: 18.1703 - val_mae: 2.7660\n",
      "Epoch 171/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5314 - mae: 1.9463 - val_loss: 18.1132 - val_mae: 2.8047\n",
      "Epoch 172/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.6151 - mae: 1.9448 - val_loss: 18.2565 - val_mae: 2.7977\n",
      "Epoch 173/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5558 - mae: 1.9349 - val_loss: 17.9952 - val_mae: 2.7613\n",
      "Epoch 174/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5089 - mae: 1.9436 - val_loss: 18.3246 - val_mae: 2.8156\n",
      "Epoch 175/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5679 - mae: 1.9412 - val_loss: 18.0601 - val_mae: 2.8010\n",
      "Epoch 176/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5200 - mae: 1.9369 - val_loss: 17.9871 - val_mae: 2.7657\n",
      "Epoch 177/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5239 - mae: 1.9268 - val_loss: 18.1681 - val_mae: 2.7741\n",
      "Epoch 178/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4958 - mae: 1.9243 - val_loss: 18.1054 - val_mae: 2.7802\n",
      "Epoch 179/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5100 - mae: 1.9245 - val_loss: 18.0334 - val_mae: 2.7656\n",
      "Epoch 180/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4951 - mae: 1.9297 - val_loss: 18.1311 - val_mae: 2.7873\n",
      "Epoch 181/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4520 - mae: 1.9431 - val_loss: 18.3142 - val_mae: 2.7965\n",
      "Epoch 182/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.5038 - mae: 1.9377 - val_loss: 18.2329 - val_mae: 2.8073\n",
      "Epoch 183/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4604 - mae: 1.9173 - val_loss: 18.1367 - val_mae: 2.7910\n",
      "Epoch 184/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4167 - mae: 1.9294 - val_loss: 18.1416 - val_mae: 2.7971\n",
      "Epoch 185/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4230 - mae: 1.9222 - val_loss: 18.0494 - val_mae: 2.7719\n",
      "Epoch 186/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3966 - mae: 1.9216 - val_loss: 18.0287 - val_mae: 2.7614\n",
      "Epoch 187/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.4072 - mae: 1.9236 - val_loss: 18.0428 - val_mae: 2.7708\n",
      "Epoch 188/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3473 - mae: 1.9047 - val_loss: 18.0011 - val_mae: 2.7573\n",
      "Epoch 189/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3441 - mae: 1.9334 - val_loss: 18.1378 - val_mae: 2.7951\n",
      "Epoch 190/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3441 - mae: 1.9135 - val_loss: 18.0633 - val_mae: 2.7509\n",
      "Epoch 191/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3683 - mae: 1.9134 - val_loss: 18.0346 - val_mae: 2.7734\n",
      "Epoch 192/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2637 - mae: 1.8993 - val_loss: 18.0138 - val_mae: 2.7710\n",
      "Epoch 193/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3513 - mae: 1.9237 - val_loss: 18.1044 - val_mae: 2.7718\n",
      "Epoch 194/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2873 - mae: 1.8999 - val_loss: 17.9114 - val_mae: 2.7324\n",
      "Epoch 195/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3479 - mae: 1.9142 - val_loss: 17.9489 - val_mae: 2.7339\n",
      "Epoch 196/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2837 - mae: 1.9098 - val_loss: 17.9034 - val_mae: 2.7606\n",
      "Epoch 197/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3315 - mae: 1.9096 - val_loss: 17.8279 - val_mae: 2.7373\n",
      "Epoch 198/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2631 - mae: 1.8964 - val_loss: 17.7465 - val_mae: 2.7218\n",
      "Epoch 199/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2606 - mae: 1.9098 - val_loss: 18.0336 - val_mae: 2.7543\n",
      "Epoch 200/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2517 - mae: 1.9076 - val_loss: 18.1232 - val_mae: 2.8387\n",
      "Epoch 201/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.3062 - mae: 1.9067 - val_loss: 17.8469 - val_mae: 2.7319\n",
      "Epoch 202/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2210 - mae: 1.9015 - val_loss: 17.8405 - val_mae: 2.7243\n",
      "Epoch 203/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2242 - mae: 1.9035 - val_loss: 18.1039 - val_mae: 2.7572\n",
      "Epoch 204/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2497 - mae: 1.9047 - val_loss: 17.9181 - val_mae: 2.7278\n",
      "Epoch 205/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2433 - mae: 1.8948 - val_loss: 18.1393 - val_mae: 2.8290\n",
      "Epoch 206/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2340 - mae: 1.9116 - val_loss: 17.9801 - val_mae: 2.7597\n",
      "Epoch 207/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1947 - mae: 1.8922 - val_loss: 17.7819 - val_mae: 2.7148\n",
      "Epoch 208/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1653 - mae: 1.8927 - val_loss: 17.9369 - val_mae: 2.7976\n",
      "Epoch 209/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.2174 - mae: 1.9012 - val_loss: 17.9967 - val_mae: 2.7973\n",
      "Epoch 210/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1850 - mae: 1.8927 - val_loss: 17.8326 - val_mae: 2.7541\n",
      "Epoch 211/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1817 - mae: 1.8937 - val_loss: 17.9040 - val_mae: 2.7582\n",
      "Epoch 212/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1085 - mae: 1.8800 - val_loss: 17.8242 - val_mae: 2.7293\n",
      "Epoch 213/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1773 - mae: 1.8985 - val_loss: 17.9394 - val_mae: 2.7162\n",
      "Epoch 214/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1934 - mae: 1.8867 - val_loss: 17.9746 - val_mae: 2.7346\n",
      "Epoch 215/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1147 - mae: 1.8727 - val_loss: 17.8306 - val_mae: 2.7043\n",
      "Epoch 216/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1243 - mae: 1.8760 - val_loss: 17.7971 - val_mae: 2.7020\n",
      "Epoch 217/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1197 - mae: 1.8850 - val_loss: 18.0082 - val_mae: 2.7374\n",
      "Epoch 218/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1565 - mae: 1.8886 - val_loss: 17.7874 - val_mae: 2.7020\n",
      "Epoch 219/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1538 - mae: 1.8902 - val_loss: 17.7757 - val_mae: 2.7201\n",
      "Epoch 220/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.1331 - mae: 1.8743 - val_loss: 17.8528 - val_mae: 2.7376\n",
      "Epoch 221/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0276 - mae: 1.8765 - val_loss: 17.7970 - val_mae: 2.7610\n",
      "Epoch 222/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0908 - mae: 1.8809 - val_loss: 17.8112 - val_mae: 2.6992\n",
      "Epoch 223/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0478 - mae: 1.8744 - val_loss: 17.7480 - val_mae: 2.7104\n",
      "Epoch 224/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0622 - mae: 1.8759 - val_loss: 17.9132 - val_mae: 2.7666\n",
      "Epoch 225/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0766 - mae: 1.8778 - val_loss: 17.9045 - val_mae: 2.7452\n",
      "Epoch 226/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0265 - mae: 1.8723 - val_loss: 18.0105 - val_mae: 2.7746\n",
      "Epoch 227/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0914 - mae: 1.8803 - val_loss: 17.8414 - val_mae: 2.7330\n",
      "Epoch 228/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9948 - mae: 1.8539 - val_loss: 17.6346 - val_mae: 2.6760\n",
      "Epoch 229/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0111 - mae: 1.8719 - val_loss: 17.6411 - val_mae: 2.7029\n",
      "Epoch 230/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9926 - mae: 1.8775 - val_loss: 17.9735 - val_mae: 2.7379\n",
      "Epoch 231/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9636 - mae: 1.8571 - val_loss: 17.8195 - val_mae: 2.7510\n",
      "Epoch 232/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9917 - mae: 1.8584 - val_loss: 17.7877 - val_mae: 2.7198\n",
      "Epoch 233/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0005 - mae: 1.8627 - val_loss: 17.7789 - val_mae: 2.7730\n",
      "Epoch 234/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9765 - mae: 1.8613 - val_loss: 17.8853 - val_mae: 2.7202\n",
      "Epoch 235/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 7.0263 - mae: 1.8527 - val_loss: 17.6163 - val_mae: 2.6887\n",
      "Epoch 236/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9570 - mae: 1.8606 - val_loss: 17.7847 - val_mae: 2.7762\n",
      "Epoch 237/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9568 - mae: 1.8494 - val_loss: 17.8601 - val_mae: 2.7818\n",
      "Epoch 238/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9956 - mae: 1.8722 - val_loss: 17.6706 - val_mae: 2.7295\n",
      "Epoch 239/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8940 - mae: 1.8587 - val_loss: 17.9492 - val_mae: 2.8204\n",
      "Epoch 240/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9464 - mae: 1.8500 - val_loss: 17.9322 - val_mae: 2.8236\n",
      "Epoch 241/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9869 - mae: 1.8534 - val_loss: 17.7445 - val_mae: 2.7407\n",
      "Epoch 242/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9628 - mae: 1.8417 - val_loss: 17.6310 - val_mae: 2.7588\n",
      "Epoch 243/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9201 - mae: 1.8460 - val_loss: 17.5456 - val_mae: 2.7395\n",
      "Epoch 244/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9615 - mae: 1.8501 - val_loss: 17.5938 - val_mae: 2.7321\n",
      "Epoch 245/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8980 - mae: 1.8325 - val_loss: 17.5927 - val_mae: 2.6949\n",
      "Epoch 246/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9149 - mae: 1.8381 - val_loss: 17.6894 - val_mae: 2.7102\n",
      "Epoch 247/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.9181 - mae: 1.8420 - val_loss: 17.5339 - val_mae: 2.7090\n",
      "Epoch 248/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8883 - mae: 1.8364 - val_loss: 17.7035 - val_mae: 2.7465\n",
      "Epoch 249/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8827 - mae: 1.8408 - val_loss: 17.6348 - val_mae: 2.7611\n",
      "Epoch 250/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8546 - mae: 1.8151 - val_loss: 17.3848 - val_mae: 2.6883\n",
      "Epoch 251/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8911 - mae: 1.8495 - val_loss: 17.4304 - val_mae: 2.7027\n",
      "Epoch 252/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8585 - mae: 1.8463 - val_loss: 17.5051 - val_mae: 2.7091\n",
      "Epoch 253/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8346 - mae: 1.8486 - val_loss: 17.5731 - val_mae: 2.7433\n",
      "Epoch 254/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8700 - mae: 1.8466 - val_loss: 17.5056 - val_mae: 2.7038\n",
      "Epoch 255/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8468 - mae: 1.8297 - val_loss: 17.4999 - val_mae: 2.6815\n",
      "Epoch 256/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8600 - mae: 1.8317 - val_loss: 17.4799 - val_mae: 2.6962\n",
      "Epoch 257/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8230 - mae: 1.8281 - val_loss: 17.4844 - val_mae: 2.7180\n",
      "Epoch 258/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8494 - mae: 1.8406 - val_loss: 17.5189 - val_mae: 2.6950\n",
      "Epoch 259/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.8035 - mae: 1.8241 - val_loss: 17.3498 - val_mae: 2.7020\n",
      "Epoch 260/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7892 - mae: 1.8550 - val_loss: 17.4789 - val_mae: 2.7495\n",
      "Epoch 261/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7940 - mae: 1.8325 - val_loss: 17.5207 - val_mae: 2.7320\n",
      "Epoch 262/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7990 - mae: 1.8216 - val_loss: 17.4365 - val_mae: 2.6762\n",
      "Epoch 263/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7986 - mae: 1.8473 - val_loss: 17.5048 - val_mae: 2.7444\n",
      "Epoch 264/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7353 - mae: 1.8303 - val_loss: 17.4832 - val_mae: 2.6895\n",
      "Epoch 265/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7952 - mae: 1.8294 - val_loss: 17.4334 - val_mae: 2.7665\n",
      "Epoch 266/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7567 - mae: 1.8335 - val_loss: 17.5615 - val_mae: 2.7223\n",
      "Epoch 267/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7911 - mae: 1.8283 - val_loss: 17.4772 - val_mae: 2.7484\n",
      "Epoch 268/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7916 - mae: 1.8271 - val_loss: 17.3938 - val_mae: 2.7339\n",
      "Epoch 269/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7650 - mae: 1.8132 - val_loss: 17.2356 - val_mae: 2.6748\n",
      "Epoch 270/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7393 - mae: 1.8192 - val_loss: 17.1208 - val_mae: 2.6766\n",
      "Epoch 271/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7434 - mae: 1.8336 - val_loss: 17.2337 - val_mae: 2.7007\n",
      "Epoch 272/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7533 - mae: 1.8174 - val_loss: 17.1737 - val_mae: 2.6831\n",
      "Epoch 273/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7489 - mae: 1.8345 - val_loss: 17.3464 - val_mae: 2.7166\n",
      "Epoch 274/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7025 - mae: 1.8064 - val_loss: 17.2000 - val_mae: 2.6708\n",
      "Epoch 275/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.7407 - mae: 1.8275 - val_loss: 17.3537 - val_mae: 2.7217\n",
      "Epoch 276/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6857 - mae: 1.8228 - val_loss: 17.4074 - val_mae: 2.7411\n",
      "Epoch 277/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6975 - mae: 1.8055 - val_loss: 17.1614 - val_mae: 2.6757\n",
      "Epoch 278/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6824 - mae: 1.8184 - val_loss: 17.2118 - val_mae: 2.6769\n",
      "Epoch 279/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6540 - mae: 1.8060 - val_loss: 17.1265 - val_mae: 2.6898\n",
      "Epoch 280/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6541 - mae: 1.8164 - val_loss: 17.2998 - val_mae: 2.7593\n",
      "Epoch 281/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6944 - mae: 1.8151 - val_loss: 17.2256 - val_mae: 2.7082\n",
      "Epoch 282/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6518 - mae: 1.8046 - val_loss: 17.1280 - val_mae: 2.6694\n",
      "Epoch 283/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6441 - mae: 1.8136 - val_loss: 17.3266 - val_mae: 2.7566\n",
      "Epoch 284/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6612 - mae: 1.8146 - val_loss: 17.2419 - val_mae: 2.7408\n",
      "Epoch 285/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5847 - mae: 1.8074 - val_loss: 17.4614 - val_mae: 2.7285\n",
      "Epoch 286/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6842 - mae: 1.8058 - val_loss: 17.1879 - val_mae: 2.6666\n",
      "Epoch 287/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5747 - mae: 1.8136 - val_loss: 17.3725 - val_mae: 2.7400\n",
      "Epoch 288/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6240 - mae: 1.8089 - val_loss: 17.3528 - val_mae: 2.7531\n",
      "Epoch 289/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6337 - mae: 1.8093 - val_loss: 17.1871 - val_mae: 2.7017\n",
      "Epoch 290/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6339 - mae: 1.8141 - val_loss: 17.2234 - val_mae: 2.7229\n",
      "Epoch 291/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5708 - mae: 1.7927 - val_loss: 17.0418 - val_mae: 2.6375\n",
      "Epoch 292/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6283 - mae: 1.8216 - val_loss: 17.2535 - val_mae: 2.7524\n",
      "Epoch 293/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5771 - mae: 1.7957 - val_loss: 17.1894 - val_mae: 2.6992\n",
      "Epoch 294/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5935 - mae: 1.8066 - val_loss: 17.1995 - val_mae: 2.7487\n",
      "Epoch 295/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5859 - mae: 1.8093 - val_loss: 17.2450 - val_mae: 2.7200\n",
      "Epoch 296/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5815 - mae: 1.7862 - val_loss: 17.3231 - val_mae: 2.7279\n",
      "Epoch 297/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5692 - mae: 1.7885 - val_loss: 17.0417 - val_mae: 2.6972\n",
      "Epoch 298/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5647 - mae: 1.8171 - val_loss: 17.2791 - val_mae: 2.7381\n",
      "Epoch 299/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.6030 - mae: 1.7880 - val_loss: 17.1799 - val_mae: 2.7305\n",
      "Epoch 300/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5290 - mae: 1.7912 - val_loss: 17.2108 - val_mae: 2.7473\n",
      "Epoch 301/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4671 - mae: 1.7950 - val_loss: 17.1485 - val_mae: 2.6989\n",
      "Epoch 302/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5490 - mae: 1.7916 - val_loss: 17.3455 - val_mae: 2.7698\n",
      "Epoch 303/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5336 - mae: 1.8205 - val_loss: 17.1727 - val_mae: 2.7399\n",
      "Epoch 304/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5662 - mae: 1.7937 - val_loss: 17.1599 - val_mae: 2.7418\n",
      "Epoch 305/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5195 - mae: 1.7934 - val_loss: 17.1605 - val_mae: 2.7314\n",
      "Epoch 306/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5164 - mae: 1.7806 - val_loss: 16.9882 - val_mae: 2.7139\n",
      "Epoch 307/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5544 - mae: 1.7943 - val_loss: 16.9190 - val_mae: 2.6881\n",
      "Epoch 308/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5056 - mae: 1.7831 - val_loss: 17.1667 - val_mae: 2.7341\n",
      "Epoch 309/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5017 - mae: 1.7916 - val_loss: 16.9351 - val_mae: 2.7053\n",
      "Epoch 310/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4697 - mae: 1.7894 - val_loss: 17.3261 - val_mae: 2.8103\n",
      "Epoch 311/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4816 - mae: 1.7907 - val_loss: 17.1824 - val_mae: 2.7475\n",
      "Epoch 312/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4800 - mae: 1.7794 - val_loss: 17.1556 - val_mae: 2.7529\n",
      "Epoch 313/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4998 - mae: 1.8026 - val_loss: 17.3441 - val_mae: 2.7539\n",
      "Epoch 314/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4813 - mae: 1.7802 - val_loss: 16.8994 - val_mae: 2.6891\n",
      "Epoch 315/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4828 - mae: 1.7822 - val_loss: 17.0556 - val_mae: 2.7341\n",
      "Epoch 316/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4700 - mae: 1.7813 - val_loss: 17.0863 - val_mae: 2.7280\n",
      "Epoch 317/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4538 - mae: 1.7874 - val_loss: 16.9981 - val_mae: 2.6726\n",
      "Epoch 318/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4584 - mae: 1.7901 - val_loss: 17.1891 - val_mae: 2.7427\n",
      "Epoch 319/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4564 - mae: 1.7891 - val_loss: 17.0576 - val_mae: 2.7094\n",
      "Epoch 320/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4615 - mae: 1.7817 - val_loss: 17.0804 - val_mae: 2.7296\n",
      "Epoch 321/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4161 - mae: 1.7664 - val_loss: 16.8666 - val_mae: 2.6484\n",
      "Epoch 322/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.5079 - mae: 1.7862 - val_loss: 17.1099 - val_mae: 2.6886\n",
      "Epoch 323/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4297 - mae: 1.7786 - val_loss: 17.1277 - val_mae: 2.7113\n",
      "Epoch 324/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4205 - mae: 1.7683 - val_loss: 17.1425 - val_mae: 2.7205\n",
      "Epoch 325/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3930 - mae: 1.7782 - val_loss: 17.1055 - val_mae: 2.7659\n",
      "Epoch 326/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4160 - mae: 1.7742 - val_loss: 16.9236 - val_mae: 2.6706\n",
      "Epoch 327/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4076 - mae: 1.7762 - val_loss: 17.0622 - val_mae: 2.7465\n",
      "Epoch 328/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3896 - mae: 1.7738 - val_loss: 17.1059 - val_mae: 2.7131\n",
      "Epoch 329/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3965 - mae: 1.7546 - val_loss: 16.9869 - val_mae: 2.6614\n",
      "Epoch 330/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.4155 - mae: 1.7772 - val_loss: 17.1554 - val_mae: 2.7112\n",
      "Epoch 331/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3881 - mae: 1.7678 - val_loss: 17.1733 - val_mae: 2.7671\n",
      "Epoch 332/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3754 - mae: 1.7826 - val_loss: 17.3181 - val_mae: 2.8127\n",
      "Epoch 333/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.3833 - mae: 1.7763 - val_loss: 17.1179 - val_mae: 2.7304\n",
      "Epoch 334/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3817 - mae: 1.7637 - val_loss: 17.1076 - val_mae: 2.7305\n",
      "Epoch 335/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3692 - mae: 1.7814 - val_loss: 17.1300 - val_mae: 2.7536\n",
      "Epoch 336/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3704 - mae: 1.7649 - val_loss: 17.0101 - val_mae: 2.7048\n",
      "Epoch 337/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3280 - mae: 1.7665 - val_loss: 16.9435 - val_mae: 2.6863\n",
      "Epoch 338/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3810 - mae: 1.7728 - val_loss: 17.1569 - val_mae: 2.7007\n",
      "Epoch 339/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3419 - mae: 1.7674 - val_loss: 17.2635 - val_mae: 2.7293\n",
      "Epoch 340/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3887 - mae: 1.7681 - val_loss: 17.1402 - val_mae: 2.7384\n",
      "Epoch 341/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3480 - mae: 1.7546 - val_loss: 17.2802 - val_mae: 2.7721\n",
      "Epoch 342/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2765 - mae: 1.7592 - val_loss: 17.0888 - val_mae: 2.6980\n",
      "Epoch 343/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3462 - mae: 1.7659 - val_loss: 17.2635 - val_mae: 2.7548\n",
      "Epoch 344/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3456 - mae: 1.7467 - val_loss: 16.9962 - val_mae: 2.7258\n",
      "Epoch 345/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2881 - mae: 1.7507 - val_loss: 16.8791 - val_mae: 2.6571\n",
      "Epoch 346/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3120 - mae: 1.7645 - val_loss: 17.1751 - val_mae: 2.7884\n",
      "Epoch 347/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3629 - mae: 1.7682 - val_loss: 17.0678 - val_mae: 2.7315\n",
      "Epoch 348/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3367 - mae: 1.7603 - val_loss: 17.0197 - val_mae: 2.7079\n",
      "Epoch 349/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3247 - mae: 1.7539 - val_loss: 17.0920 - val_mae: 2.7516\n",
      "Epoch 350/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2864 - mae: 1.7777 - val_loss: 17.1993 - val_mae: 2.7530\n",
      "Epoch 351/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2806 - mae: 1.7442 - val_loss: 17.2908 - val_mae: 2.7728\n",
      "Epoch 352/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2977 - mae: 1.7524 - val_loss: 17.0357 - val_mae: 2.6741\n",
      "Epoch 353/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2380 - mae: 1.7611 - val_loss: 17.4239 - val_mae: 2.8216\n",
      "Epoch 354/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2941 - mae: 1.7582 - val_loss: 17.0559 - val_mae: 2.6961\n",
      "Epoch 355/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2913 - mae: 1.7579 - val_loss: 16.9560 - val_mae: 2.6837\n",
      "Epoch 356/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2990 - mae: 1.7734 - val_loss: 16.9665 - val_mae: 2.6784\n",
      "Epoch 357/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.3119 - mae: 1.7612 - val_loss: 17.0594 - val_mae: 2.6849\n",
      "Epoch 358/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2679 - mae: 1.7569 - val_loss: 17.0794 - val_mae: 2.6960\n",
      "Epoch 359/500\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.2841 - mae: 1.7626 - val_loss: 17.2550 - val_mae: 2.7660\n",
      "Epoch 360/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2787 - mae: 1.7603 - val_loss: 17.1014 - val_mae: 2.6859\n",
      "Epoch 361/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2443 - mae: 1.7478 - val_loss: 17.4744 - val_mae: 2.8151\n",
      "Epoch 362/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2606 - mae: 1.7602 - val_loss: 17.3132 - val_mae: 2.7736\n",
      "Epoch 363/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2210 - mae: 1.7417 - val_loss: 17.1449 - val_mae: 2.7156\n",
      "Epoch 364/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1995 - mae: 1.7633 - val_loss: 17.3179 - val_mae: 2.7687\n",
      "Epoch 365/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2558 - mae: 1.7415 - val_loss: 17.2395 - val_mae: 2.7421\n",
      "Epoch 366/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2272 - mae: 1.7447 - val_loss: 17.0740 - val_mae: 2.7189\n",
      "Epoch 367/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2281 - mae: 1.7576 - val_loss: 17.2997 - val_mae: 2.7527\n",
      "Epoch 368/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2471 - mae: 1.7476 - val_loss: 17.1641 - val_mae: 2.7163\n",
      "Epoch 369/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2305 - mae: 1.7549 - val_loss: 17.2492 - val_mae: 2.7228\n",
      "Epoch 370/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2092 - mae: 1.7510 - val_loss: 17.2689 - val_mae: 2.7233\n",
      "Epoch 371/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2009 - mae: 1.7381 - val_loss: 17.1654 - val_mae: 2.7238\n",
      "Epoch 372/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2035 - mae: 1.7597 - val_loss: 17.3313 - val_mae: 2.7274\n",
      "Epoch 373/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2036 - mae: 1.7264 - val_loss: 17.3963 - val_mae: 2.7820\n",
      "Epoch 374/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2155 - mae: 1.7484 - val_loss: 17.0885 - val_mae: 2.6830\n",
      "Epoch 375/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2437 - mae: 1.7506 - val_loss: 17.2731 - val_mae: 2.7505\n",
      "Epoch 376/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2183 - mae: 1.7487 - val_loss: 17.1864 - val_mae: 2.7551\n",
      "Epoch 377/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1767 - mae: 1.7386 - val_loss: 16.9980 - val_mae: 2.6686\n",
      "Epoch 378/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1888 - mae: 1.7546 - val_loss: 17.0901 - val_mae: 2.7434\n",
      "Epoch 379/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2129 - mae: 1.7514 - val_loss: 16.9903 - val_mae: 2.6789\n",
      "Epoch 380/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1689 - mae: 1.7549 - val_loss: 17.0283 - val_mae: 2.7307\n",
      "Epoch 381/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2047 - mae: 1.7456 - val_loss: 16.8591 - val_mae: 2.6930\n",
      "Epoch 382/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1690 - mae: 1.7524 - val_loss: 17.0963 - val_mae: 2.7553\n",
      "Epoch 383/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2024 - mae: 1.7463 - val_loss: 17.1138 - val_mae: 2.7294\n",
      "Epoch 384/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2081 - mae: 1.7553 - val_loss: 17.0682 - val_mae: 2.7192\n",
      "Epoch 385/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1803 - mae: 1.7397 - val_loss: 17.0443 - val_mae: 2.7009\n",
      "Epoch 386/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1265 - mae: 1.7337 - val_loss: 16.9545 - val_mae: 2.7077\n",
      "Epoch 387/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.2029 - mae: 1.7464 - val_loss: 17.0343 - val_mae: 2.7101\n",
      "Epoch 388/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1767 - mae: 1.7323 - val_loss: 16.9384 - val_mae: 2.6998\n",
      "Epoch 389/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0803 - mae: 1.7344 - val_loss: 17.4674 - val_mae: 2.7859\n",
      "Epoch 390/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1695 - mae: 1.7259 - val_loss: 17.0400 - val_mae: 2.7307\n",
      "Epoch 391/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1744 - mae: 1.7424 - val_loss: 16.9772 - val_mae: 2.6864\n",
      "Epoch 392/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1533 - mae: 1.7397 - val_loss: 17.0104 - val_mae: 2.7085\n",
      "Epoch 393/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1350 - mae: 1.7278 - val_loss: 17.0067 - val_mae: 2.6906\n",
      "Epoch 394/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1187 - mae: 1.7361 - val_loss: 16.8102 - val_mae: 2.6414\n",
      "Epoch 395/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1698 - mae: 1.7672 - val_loss: 16.8689 - val_mae: 2.6485\n",
      "Epoch 396/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1465 - mae: 1.7554 - val_loss: 17.0477 - val_mae: 2.7003\n",
      "Epoch 397/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0885 - mae: 1.7346 - val_loss: 17.1416 - val_mae: 2.7441\n",
      "Epoch 398/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0656 - mae: 1.7501 - val_loss: 17.0883 - val_mae: 2.7582\n",
      "Epoch 399/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0972 - mae: 1.7306 - val_loss: 16.8930 - val_mae: 2.6682\n",
      "Epoch 400/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1323 - mae: 1.7455 - val_loss: 17.1094 - val_mae: 2.7453\n",
      "Epoch 401/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1355 - mae: 1.7309 - val_loss: 17.1255 - val_mae: 2.7353\n",
      "Epoch 402/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0728 - mae: 1.7369 - val_loss: 17.2961 - val_mae: 2.7979\n",
      "Epoch 403/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1082 - mae: 1.7157 - val_loss: 17.1206 - val_mae: 2.7323\n",
      "Epoch 404/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1080 - mae: 1.7314 - val_loss: 17.1684 - val_mae: 2.7268\n",
      "Epoch 405/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1281 - mae: 1.7217 - val_loss: 17.1244 - val_mae: 2.7320\n",
      "Epoch 406/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0500 - mae: 1.7232 - val_loss: 17.3232 - val_mae: 2.7850\n",
      "Epoch 407/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0560 - mae: 1.7111 - val_loss: 16.7814 - val_mae: 2.6750\n",
      "Epoch 408/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1142 - mae: 1.7489 - val_loss: 16.9676 - val_mae: 2.7209\n",
      "Epoch 409/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0758 - mae: 1.7285 - val_loss: 16.9528 - val_mae: 2.6999\n",
      "Epoch 410/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.1050 - mae: 1.7360 - val_loss: 17.0178 - val_mae: 2.7077\n",
      "Epoch 411/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0894 - mae: 1.7356 - val_loss: 17.2565 - val_mae: 2.7851\n",
      "Epoch 412/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0526 - mae: 1.7297 - val_loss: 17.1346 - val_mae: 2.7274\n",
      "Epoch 413/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0497 - mae: 1.7183 - val_loss: 17.1415 - val_mae: 2.7166\n",
      "Epoch 414/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0669 - mae: 1.7385 - val_loss: 17.3524 - val_mae: 2.7615\n",
      "Epoch 415/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0063 - mae: 1.7092 - val_loss: 17.3646 - val_mae: 2.8093\n",
      "Epoch 416/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0913 - mae: 1.7365 - val_loss: 17.2246 - val_mae: 2.7337\n",
      "Epoch 417/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0928 - mae: 1.7177 - val_loss: 17.1327 - val_mae: 2.7154\n",
      "Epoch 418/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0241 - mae: 1.7422 - val_loss: 17.0975 - val_mae: 2.7152\n",
      "Epoch 419/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0471 - mae: 1.7176 - val_loss: 17.0314 - val_mae: 2.6866\n",
      "Epoch 420/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0162 - mae: 1.7280 - val_loss: 16.9913 - val_mae: 2.6903\n",
      "Epoch 421/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0156 - mae: 1.7099 - val_loss: 17.0949 - val_mae: 2.7708\n",
      "Epoch 422/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0491 - mae: 1.7135 - val_loss: 17.0522 - val_mae: 2.7477\n",
      "Epoch 423/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9860 - mae: 1.7044 - val_loss: 16.9932 - val_mae: 2.7108\n",
      "Epoch 424/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0646 - mae: 1.7210 - val_loss: 17.0131 - val_mae: 2.7121\n",
      "Epoch 425/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9896 - mae: 1.7288 - val_loss: 17.3173 - val_mae: 2.8124\n",
      "Epoch 426/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0253 - mae: 1.7305 - val_loss: 17.2791 - val_mae: 2.8100\n",
      "Epoch 427/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0580 - mae: 1.7308 - val_loss: 17.0145 - val_mae: 2.6994\n",
      "Epoch 428/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0318 - mae: 1.7103 - val_loss: 17.0111 - val_mae: 2.7041\n",
      "Epoch 429/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0157 - mae: 1.7218 - val_loss: 17.0096 - val_mae: 2.6915\n",
      "Epoch 430/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0033 - mae: 1.7253 - val_loss: 17.0162 - val_mae: 2.7150\n",
      "Epoch 431/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9914 - mae: 1.7245 - val_loss: 16.9008 - val_mae: 2.6649\n",
      "Epoch 432/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9972 - mae: 1.7234 - val_loss: 17.2213 - val_mae: 2.7774\n",
      "Epoch 433/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9949 - mae: 1.7173 - val_loss: 17.2139 - val_mae: 2.7798\n",
      "Epoch 434/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8941 - mae: 1.6934 - val_loss: 17.0512 - val_mae: 2.7029\n",
      "Epoch 435/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0127 - mae: 1.7162 - val_loss: 17.3219 - val_mae: 2.8005\n",
      "Epoch 436/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9929 - mae: 1.7166 - val_loss: 17.1155 - val_mae: 2.7071\n",
      "Epoch 437/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9925 - mae: 1.7181 - val_loss: 17.0522 - val_mae: 2.6979\n",
      "Epoch 438/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9002 - mae: 1.7210 - val_loss: 17.2712 - val_mae: 2.7452\n",
      "Epoch 439/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0213 - mae: 1.7127 - val_loss: 17.0198 - val_mae: 2.7056\n",
      "Epoch 440/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9785 - mae: 1.7315 - val_loss: 17.1613 - val_mae: 2.7669\n",
      "Epoch 441/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9589 - mae: 1.7229 - val_loss: 17.2152 - val_mae: 2.7871\n",
      "Epoch 442/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9911 - mae: 1.7114 - val_loss: 17.2706 - val_mae: 2.7878\n",
      "Epoch 443/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 6.0070 - mae: 1.7326 - val_loss: 17.2064 - val_mae: 2.7647\n",
      "Epoch 444/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9389 - mae: 1.7020 - val_loss: 17.3990 - val_mae: 2.8136\n",
      "Epoch 445/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9991 - mae: 1.7006 - val_loss: 17.1456 - val_mae: 2.7022\n",
      "Epoch 446/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9182 - mae: 1.7204 - val_loss: 17.4407 - val_mae: 2.7711\n",
      "Epoch 447/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9741 - mae: 1.7041 - val_loss: 17.2887 - val_mae: 2.7656\n",
      "Epoch 448/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9750 - mae: 1.7018 - val_loss: 17.0394 - val_mae: 2.7197\n",
      "Epoch 449/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9503 - mae: 1.7167 - val_loss: 16.9731 - val_mae: 2.7413\n",
      "Epoch 450/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9340 - mae: 1.6980 - val_loss: 17.2443 - val_mae: 2.7967\n",
      "Epoch 451/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9390 - mae: 1.7255 - val_loss: 17.0351 - val_mae: 2.7034\n",
      "Epoch 452/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9570 - mae: 1.7174 - val_loss: 17.0039 - val_mae: 2.6962\n",
      "Epoch 453/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9207 - mae: 1.7090 - val_loss: 17.0985 - val_mae: 2.6905\n",
      "Epoch 454/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9406 - mae: 1.7089 - val_loss: 16.9806 - val_mae: 2.6631\n",
      "Epoch 455/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9008 - mae: 1.6997 - val_loss: 17.2172 - val_mae: 2.7158\n",
      "Epoch 456/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9931 - mae: 1.7192 - val_loss: 17.2468 - val_mae: 2.7488\n",
      "Epoch 457/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9280 - mae: 1.7114 - val_loss: 17.2465 - val_mae: 2.7345\n",
      "Epoch 458/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9219 - mae: 1.7191 - val_loss: 17.1578 - val_mae: 2.7154\n",
      "Epoch 459/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9063 - mae: 1.7062 - val_loss: 17.2645 - val_mae: 2.7552\n",
      "Epoch 460/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8952 - mae: 1.7201 - val_loss: 17.0329 - val_mae: 2.7033\n",
      "Epoch 461/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8981 - mae: 1.7041 - val_loss: 16.9952 - val_mae: 2.7084\n",
      "Epoch 462/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9316 - mae: 1.7305 - val_loss: 17.4192 - val_mae: 2.8267\n",
      "Epoch 463/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8909 - mae: 1.7020 - val_loss: 17.2359 - val_mae: 2.7541\n",
      "Epoch 464/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9118 - mae: 1.7286 - val_loss: 17.2947 - val_mae: 2.7728\n",
      "Epoch 465/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8609 - mae: 1.6918 - val_loss: 16.9279 - val_mae: 2.6836\n",
      "Epoch 466/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8940 - mae: 1.7108 - val_loss: 17.0280 - val_mae: 2.7186\n",
      "Epoch 467/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8471 - mae: 1.7121 - val_loss: 17.4531 - val_mae: 2.8133\n",
      "Epoch 468/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9074 - mae: 1.6930 - val_loss: 17.1746 - val_mae: 2.7333\n",
      "Epoch 469/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9163 - mae: 1.7021 - val_loss: 17.2412 - val_mae: 2.7395\n",
      "Epoch 470/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8874 - mae: 1.6997 - val_loss: 17.2106 - val_mae: 2.7461\n",
      "Epoch 471/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8871 - mae: 1.6948 - val_loss: 17.1130 - val_mae: 2.7138\n",
      "Epoch 472/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8751 - mae: 1.7114 - val_loss: 17.2203 - val_mae: 2.7529\n",
      "Epoch 473/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8681 - mae: 1.6979 - val_loss: 17.3932 - val_mae: 2.8129\n",
      "Epoch 474/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8968 - mae: 1.6998 - val_loss: 16.9381 - val_mae: 2.6863\n",
      "Epoch 475/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.9085 - mae: 1.7000 - val_loss: 17.0582 - val_mae: 2.7141\n",
      "Epoch 476/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8197 - mae: 1.7080 - val_loss: 17.2572 - val_mae: 2.7607\n",
      "Epoch 477/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8635 - mae: 1.6848 - val_loss: 16.7925 - val_mae: 2.6466\n",
      "Epoch 478/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8964 - mae: 1.7234 - val_loss: 17.0156 - val_mae: 2.6977\n",
      "Epoch 479/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8966 - mae: 1.7090 - val_loss: 17.1460 - val_mae: 2.7494\n",
      "Epoch 480/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8478 - mae: 1.7020 - val_loss: 17.2783 - val_mae: 2.8027\n",
      "Epoch 481/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.7988 - mae: 1.6967 - val_loss: 17.3406 - val_mae: 2.7973\n",
      "Epoch 482/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8739 - mae: 1.7007 - val_loss: 17.1711 - val_mae: 2.7291\n",
      "Epoch 483/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8188 - mae: 1.6936 - val_loss: 17.2163 - val_mae: 2.7567\n",
      "Epoch 484/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8684 - mae: 1.6970 - val_loss: 17.0740 - val_mae: 2.7206\n",
      "Epoch 485/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8562 - mae: 1.6941 - val_loss: 16.9821 - val_mae: 2.6984\n",
      "Epoch 486/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8579 - mae: 1.7293 - val_loss: 17.1156 - val_mae: 2.7415\n",
      "Epoch 487/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8014 - mae: 1.6967 - val_loss: 17.2832 - val_mae: 2.7805\n",
      "Epoch 488/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8996 - mae: 1.7079 - val_loss: 17.0526 - val_mae: 2.7161\n",
      "Epoch 489/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8200 - mae: 1.6985 - val_loss: 16.8727 - val_mae: 2.6911\n",
      "Epoch 490/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8673 - mae: 1.7054 - val_loss: 17.2302 - val_mae: 2.7667\n",
      "Epoch 491/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8238 - mae: 1.6920 - val_loss: 17.1601 - val_mae: 2.7622\n",
      "Epoch 492/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8399 - mae: 1.7024 - val_loss: 17.0001 - val_mae: 2.7127\n",
      "Epoch 493/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8411 - mae: 1.7044 - val_loss: 17.0315 - val_mae: 2.7286\n",
      "Epoch 494/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8395 - mae: 1.6997 - val_loss: 17.3249 - val_mae: 2.7779\n",
      "Epoch 495/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8326 - mae: 1.6969 - val_loss: 17.1036 - val_mae: 2.7084\n",
      "Epoch 496/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8394 - mae: 1.7038 - val_loss: 17.1491 - val_mae: 2.7553\n",
      "Epoch 497/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8242 - mae: 1.7151 - val_loss: 17.3070 - val_mae: 2.7817\n",
      "Epoch 498/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8100 - mae: 1.6848 - val_loss: 17.0830 - val_mae: 2.7112\n",
      "Epoch 499/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.8220 - mae: 1.6969 - val_loss: 16.9193 - val_mae: 2.6632\n",
      "Epoch 500/500\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 5.7892 - mae: 1.7033 - val_loss: 17.1404 - val_mae: 2.7336\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels, epochs=500, batch_size=16, validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9c1bdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 학습 히스토리에서 loss, val_loss, mae, val_mae를 차트로 보여줍니다.\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.plot(epochs, loss, 'b-', label='train_loss')\n",
    "ax1.plot(epochs, val_loss, 'r-', label='val_loss')\n",
    "ax1.set_title('Train and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "mae = history_dict['mae']\n",
    "val_mae = history_dict['val_mae']\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.plot(epochs, mae, 'b-', label='train_mae')\n",
    "ax2.plot(epochs, val_mae, 'r-', label='val_mae')\n",
    "ax2.set_title('Train and Validation MAE')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8911f749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 17.1404 - mae: 2.7336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17.140398025512695, 2.733560085296631]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels)\n",
    "\n",
    "# loss: 16.3494 - mae: 2.4722 옵티마이저 설정없음 batch_size=4\n",
    "# loss: 16.8409 - mae: 2.7009 optimizer='adam' batch_size=4\n",
    "# loss: 17.0557 - mae: 2.6159 옵티마이저 설정없음 batch_size=4\n",
    "# loss: 17.0971 - mae: 2.6810 옵티마이저 설정없음 batch_size=32\n",
    "# loss: 17.1404 - mae: 2.7336 옵티마이저 설정없음 batch_size=16\n",
    "# loss: 17.2247 - mae: 2.7108 옵티마이저 설정없음 epochs=500, batch_size=16\n",
    "# loss: 18.4122 - mae: 2.7153 optimizer='rmsprop' batch_size=4\n",
    "# loss: 18.1140 - mae: 2.8198 optimizer='rmsprop' batch_size=32\n",
    "# loss: 19.3903 - mae: 2.7993 옵티마이저 설정없음 batch_size=32\n",
    "# loss: 20.0950 - mae: 3.0412 optimizer='adam' batch_size=32\n",
    "# loss: 21.0823 - mae: 3.3321 옵티마이저 설정없음 batch_size=128\n",
    "# loss: 26.8171 - mae: 3.0479 optimizer='adam' batch_size=2\n",
    "# 레이어 추가 loss: 62.6193 - mae: 4.3065\n",
    "# 레이어 추가 loss: 33.4409 - mae: 3.5778 에폭 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124f30d",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "1) 데이터가 어떤 모습인지 제대로 파악되지 않은 상태에서 모델만 돌려보려니.. 감이 잘 안오지 않았다.. ㅠ 맹목적으로 따라가는 느낌이었다.\n",
    "\n",
    "2) 실제 예제를 따라갈때야 윤곽이 잡힌다. 데이터 로드, 확인, 전처리, 모델 구성, 학습, 평가의 과정이.. 조금씩 눈에 들어온다. 펀드에서도 전체적인 부분을 항상? 보여주고, 어느 부분을 집중적으로 보고 있는지 시각화해준다면.. 조금 더 눈에 들어오지 않을까 싶다.\n",
    "\n",
    "3) train_data = train_data - train_data_mean\n",
    "이 코드가 충격적이었다. 각 데이터값에서 어떻게 평균값을 뺄지 고민했는데... 아주 단순한 방법이..\n",
    "처음에는 train_data와 똑같은 shape의 mean 값을 만들어서 빼줘야하나 싶었다. 아니라서 다행.\n",
    "\n",
    "4) 회귀 모델에 # model.add(layers.Dense(10, activation='softmax'))를 적용하면, 그래프가 아주 잘못 나온다. softmax는 분류모델에만 쓰는 걸로 해야겠다.\n",
    "\n",
    "5) 레이어와 옵티마이저, 배치사이즈를 어떻게 조정하느냐에 따라 결과값이 달라졌다. 그러나 무엇이 최적인지 도대체 알 수가 없다.. ㅠㅠ 이 부분이 경험치로 채워야한다는 부분인데.. 어떻게 해결해야할지 감도 안온다.\n",
    "\n",
    "6) 이래저래 하루동안 돌려보면서 그래도 수요일에 비하면 훨씬.. 친밀하게? 다가온다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
